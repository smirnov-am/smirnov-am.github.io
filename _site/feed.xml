<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-04-10T23:08:59+02:00</updated><id>http://localhost:4000/</id><title type="html">Alexey Smirnov</title><subtitle></subtitle><entry><title type="html">E-commerce recommendation systems</title><link href="http://localhost:4000/machine/learning,/data/mining,/python/2018/04/08/E-commerce-recommendation-systems.html" rel="alternate" type="text/html" title="E-commerce recommendation systems" /><published>2018-04-08T23:01:34+02:00</published><updated>2018-04-08T23:01:34+02:00</updated><id>http://localhost:4000/machine/learning,/data/mining,/python/2018/04/08/E-commerce-recommendation-systems</id><content type="html" xml:base="http://localhost:4000/machine/learning,/data/mining,/python/2018/04/08/E-commerce-recommendation-systems.html">&lt;p&gt;Once novelty recommendation systems are used now by more and more e-commerce sites to help customers find products to purchase. For e-commerce business owners these tools facilitate cross-sales.&lt;/p&gt;

&lt;h2 id=&quot;usage&quot;&gt;Usage&lt;/h2&gt;
&lt;p&gt;Amazon is one of the most prominent organizations used recommendations to increase sales.
According to &lt;a href=&quot;http://fortune.com/2012/07/30/amazons-recommendation-secret/&quot;&gt;fortune.com&lt;/a&gt; Amazon was able to increase sales by 29% in 2012 as a result of implementing recommendation system. 
35% of Amazom’s revenue is generated by its recommendation engine &lt;a href=&quot;https://www.mckinsey.com/industries/retail/our-insights/how-retailers-can-keep-up-with-consumers&quot;&gt;(source)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Amazon is using &lt;a href=&quot;https://www.computer.org/csdl/mags/ic/2017/03/mic2017030012.html&quot;&gt;collaborative filtering approach&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;However there is another approach to mine items that a frequently bought together - &lt;strong&gt;association rule mining&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;The difference is the unit of aggregation: collaborative filtering unit is user or items.&lt;/p&gt;

&lt;p&gt;With user-to-user collaborative filtering approach algorithm finds a user which similar to you and suggests to buy the same he  bought. This is computationally difficult as there might be more users than items or users have very dissimilar interests.&lt;/p&gt;

&lt;p&gt;With item-to-item collaborative filtering approach which is used by Amazon, algorithm finds a neighborhood of items that are bought/viewed by you and users that bought viewed the same item. Then items from that neighborhood are displayed as recommendations.&lt;/p&gt;

&lt;p&gt;Association rule unit is a session (order), which makes this approach less personalized, as users and user purchase history is not taken into account.
But it has some strong points:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;it’s extremely simple and fast.&lt;/li&gt;
  &lt;li&gt;it will work with very small and sparse customer bases.&lt;/li&gt;
  &lt;li&gt;knowledge of the customer beyond what products or services they currently have is not necessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, there is one major drawback that makes association rule algorithms less favored by e-commerce - inability to catch so called “long tail”. As online stores have a lot of items and some of them are bought rarely. But among these rare items there might be a pair that are of interested to specific group of people. Association rules are unlikely to finds them.&lt;/p&gt;

&lt;p&gt;But these algorithms are useful for offline stores, where it’s not possible to track users and find application in other areas.&lt;/p&gt;

&lt;h2 id=&quot;algorithms&quot;&gt;Algorithms&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;a href=&quot;http://www.vldb.org/conf/1994/P487.PDF&quot;&gt;&lt;strong&gt;Apriori&lt;/strong&gt;&lt;/a&gt;: it was introduced in 1993 , more than 20 years ago. It remains one of the most important data mining algorithms, not because it is the fastest, but because it has influenced the development of many other algorithms &lt;a href=&quot;http://data-mining.philippe-fournier-viger.com/classic-data-mining-algorithm-1-apriori/&quot;&gt;(source)&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Apriori-TID&lt;/strong&gt;: is a variation of the Apriori algorithm. It was proposed in the same article as Apriori as an alternative implementation. It produces the same output, but does less scans 
of the transaction database&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.slideshare.net/deepa15/eclat-37310304&quot;&gt;&lt;strong&gt;Eclat&lt;/strong&gt;&lt;/a&gt;: is faster than Apriori, but less memory efficient&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://dx.doi.org/10.1145/335191.335372&quot;&gt;&lt;strong&gt;FP-Growth&lt;/strong&gt;&lt;/a&gt;: most advanced and efficient implementation of frequent pattern mining&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;input-parameters&quot;&gt;Input parameters&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;order list&lt;/em&gt;: database of all orders (transactions). Each entry is a subset of all items that are being sold (here item count is dropped)&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Example:&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1 {item1, item3, item4}
2 {item2, item3, item5}
3 {item1, item2, item3, item5}
4 {item2, item5}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;list of all possible items on sale&lt;/em&gt;: optional parameter that can determined by scanning order list once&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;items = {item1, item2, item3, item4, item5}&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;minimum support&lt;/em&gt;: minimum frequency for an item or itemset to count as frequent&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Example: &lt;code class=&quot;highlighter-rouge&quot;&gt;min_support=0.1&lt;/code&gt; means that we are interested in items or itemsets that appeared in minimum 10% of all orders&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;minimum confidence&lt;/em&gt;: parameter that says how likely item Y is purchased when item X is purchased, expressed as {X -&amp;gt; Y}. This is measured by the proportion of transactions with item X, in which item Y also appears&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;This can be calculated like so &lt;code class=&quot;highlighter-rouge&quot;&gt;confidence({X -&amp;gt; Y}) = support({X, Y}) / support(X)&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;em&gt;minimum lift&lt;/em&gt; (optional as not used in many implementations): parameter that says how likely item Y is purchased when item X is purchased,
while controlling for how popular item Y is. A lift value greater than 1 means that item Y is likely to be bought if item X is bought, while a value less than 1 means that item Y is unlikely to be bought if item X is bought&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
  &lt;p&gt;Formula for lift is &lt;code class=&quot;highlighter-rouge&quot;&gt;lift({X -&amp;gt; Y}) = support({X, Y}) / (support(X) * support(Y))&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;output&quot;&gt;Output:&lt;/h2&gt;
&lt;p&gt;A list of rules in a form (&lt;code class=&quot;highlighter-rouge&quot;&gt;from_itemset&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;to_itemset&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;confidence&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;lift&lt;/code&gt;), where &lt;code class=&quot;highlighter-rouge&quot;&gt;from_itemset&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;to_itemset&lt;/code&gt; are subsets of items on sale.&lt;/p&gt;

&lt;h2 id=&quot;making-a-recommendation&quot;&gt;Making a recommendation&lt;/h2&gt;

&lt;p&gt;Recommendation can be made, for example at a checkout, when user has item1 and item2 in the shopping cart. In that case &lt;code class=&quot;highlighter-rouge&quot;&gt;from_itemset = {item1, item2}&lt;/code&gt; and using the list of rules we may find respective
&lt;code class=&quot;highlighter-rouge&quot;&gt;to_itemset&lt;/code&gt; with maximum confidence and/or lift.&lt;/p&gt;

&lt;h2 id=&quot;apriori-algorithm&quot;&gt;Apriori algorithm.&lt;/h2&gt;
&lt;h3 id=&quot;1st-step&quot;&gt;1st step:&lt;/h3&gt;
&lt;p&gt;Let the &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_1&lt;/code&gt; set to contain all individual items.&lt;/p&gt;

&lt;p&gt;Now let’s calculate support for each &lt;code class=&quot;highlighter-rouge&quot;&gt;candidate&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_1&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Populate &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_1&lt;/code&gt; set with those candidates, which support is &amp;gt;= &lt;code class=&quot;highlighter-rouge&quot;&gt;min_support&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;2nd-step&quot;&gt;2nd step:&lt;/h3&gt;
&lt;p&gt;Let the &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_2&lt;/code&gt; be populated with all pairs from &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_1&lt;/code&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;For example, if &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_1 = {item1, item3, item4}&lt;/code&gt;&lt;/p&gt;

  &lt;p&gt;then &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_2 = [{item1, item3}, {item1, item4}, {item3, item4}]&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let’s calculate support for each &lt;code class=&quot;highlighter-rouge&quot;&gt;candidate&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_2&lt;/code&gt; as in previous step by going through each order in order list.
Populate &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_2&lt;/code&gt; with those candidates from &lt;code class=&quot;highlighter-rouge&quot;&gt;candidates_2&lt;/code&gt;, which support is &amp;gt;= &lt;code class=&quot;highlighter-rouge&quot;&gt;min_support&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;nth-step&quot;&gt;Nth step:&lt;/h3&gt;
&lt;p&gt;Repeat step 2 until you can form candidates sets. Candidates for a next step are formed from a layer of a current step by unions of all possible pairs in layer set.(elements of a layer should be sets to support this). This is also known as self-join.
Now we have filtered set of combinations of items and their respective support (support dictionary).&lt;/p&gt;

&lt;p&gt;In each step we populate a support dictionary using itemsets as keys and their correspondent support as values.&lt;/p&gt;

&lt;h3 id=&quot;association-rules&quot;&gt;Association rules&lt;/h3&gt;
&lt;p&gt;Next step is to calculate all association rules.
Let’s fix a hyperparameters &lt;code class=&quot;highlighter-rouge&quot;&gt;min_confidence&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;min_lift&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;For all sets &lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt; in support dictionary let’s create all non-empty subsets &lt;code class=&quot;highlighter-rouge&quot;&gt;S&lt;/code&gt; of &lt;code class=&quot;highlighter-rouge&quot;&gt;L&lt;/code&gt;, and evaluate confidence and lift for a rule &lt;code class=&quot;highlighter-rouge&quot;&gt;{S -&amp;gt; L-S}&lt;/code&gt; and save rules, whose parameters are greater of equal then minimal.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;In a notion {X -&amp;gt; Y}, X is called from-itemset, and Y - to-itemset.&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;apriori-tid&quot;&gt;Apriori-TID&lt;/h2&gt;
&lt;ul&gt;
  &lt;li&gt;the order list is not used at all for counting the support of candidate itemsets after the first pass.&lt;/li&gt;
  &lt;li&gt;the candidate itemsets are generated the same way as in Apriori algorithm&lt;/li&gt;
  &lt;li&gt;rules are generated the same way after support dictionary is populated
The only different is that in each layer &amp;gt; 1 a separate list C&lt;code class=&quot;highlighter-rouge&quot;&gt; is created.
C&lt;/code&gt; hold transaction ids with correspondent itemsets from candidates on that layer that are in that particular transaction.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For example, using order list from above first layer would yield such support dictionary:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;item1 0.5
item2 0.75
item3 0.75 
item5 0.75
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Second layer candidates set is:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{item1, item2} 0.25
{item1, item3} 0.5 *
{item1, item5} 0.25
{item2, item3} 0.5 *
{item2, item5} 0.75 *
{item3, item5} 0.5 *
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;So &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_2&lt;/code&gt; will consist from itemsets with &lt;code class=&quot;highlighter-rouge&quot;&gt;*&lt;/code&gt;. And at this step we create a separate data structure to hold transaction IDs for these sets that made it to &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_2&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;1 {item1, item3}
2 {item2, item3} {item2, item5} {item3, item5}
3 {item1, item2} {item1, item3} {item1, item5} {item2, item3} {item2, item5} {item3, item5}
4 {item2, item5}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;Using this additional list we will calculate support for candidates for &lt;code class=&quot;highlighter-rouge&quot;&gt;layer_3&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;eclat&quot;&gt;Eclat&lt;/h2&gt;
&lt;p&gt;Another way to speedup support calculation is to keep a list of transaction ids for every itemset at each layer. It speeds up support calculation even more. but these transaction lists can be large in size.&lt;/p&gt;

&lt;p&gt;Again using the same order list in first step, transaction ID list will be&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;item1 1, 3
item2 2, 3, 4
item3 1, 2, 3
item4 1
item5 2, 3, 4
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;item4 won’t be included in the next layer, and this list can help us to calculate lists for all possible pairs for the next step:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{item1 item2} 3
{item1 item3} 1, 3
{item1 item4} 1
{item1 item5} 3
{item2 item3} 2, 3
...etc
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;fp-growth&quot;&gt;FP-Growth&lt;/h2&gt;
&lt;p&gt;This one is different from Apriori-like algorithms in a way that candidate itemsets are not generated explicitly. FP-growth uses a suffix tree (FP-tree) structure to encode transactions thus speeds up support calculation.&lt;/p&gt;

&lt;h2 id=&quot;tests&quot;&gt;Tests&lt;/h2&gt;
&lt;p&gt;Dataset was taken from http://archive.ics.uci.edu/ml/datasets/Online+Retail &lt;em&gt;Daqing Chen, Sai Liang Sain, and Kun Guo, Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining, Journal of Database Marketing and Customer Strategy Management, Vol. 19, No. 3, pp. 197â€“208, 2012 (Published online before print: 27 August 2012. doi: 10.1057/dbm.2012.17).&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;preprocessing&quot;&gt;Preprocessing&lt;/h3&gt;
&lt;p&gt;As each row contains &lt;code class=&quot;highlighter-rouge&quot;&gt;InvoiceNo&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;StockCode&lt;/code&gt;, let’s group items by &lt;code class=&quot;highlighter-rouge&quot;&gt;InvoiceNo&lt;/code&gt;&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import csv
from collections import defaultdict

order_list = defaultdict(list)

with open('data.csv', encoding=&quot;iso-8859-1&quot;) as f:
    csv_reader = csv.DictReader(f)
    for row in csv_reader:
        order_list[row['InvoiceNo']].append(row['StockCode'])
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Some stats of the dataset:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;number of orders: 25900&lt;/li&gt;
  &lt;li&gt;4070 items on sale&lt;/li&gt;
  &lt;li&gt;minimum order: 1 item&lt;/li&gt;
  &lt;li&gt;maximum order: 1114 items&lt;/li&gt;
  &lt;li&gt;mean order size: ~21 items&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;python-implementation&quot;&gt;Python implementation&lt;/h3&gt;
&lt;p&gt;I’ve implemented all 4 aforementioned algorithms &lt;a href=&quot;https://github.com/smirnov-am/pyfreqpm&quot;&gt;here&lt;/a&gt;. 
FP-Growth needs some more testing though, so I’ve used &lt;a href=&quot;https://spark.apache.org/docs/2.3.0/mllib-frequent-pattern-mining.html&quot;&gt;Apache Spark&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Running times with &lt;code class=&quot;highlighter-rouge&quot;&gt;min_support=0.03&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;min_confidence=0.5&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;min_lift=1.0&lt;/code&gt; are:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Algorithm&lt;/th&gt;
      &lt;th&gt;run time, s&lt;/th&gt;
      &lt;th&gt;memmory used, MB&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;apriori-gen&lt;/td&gt;
      &lt;td&gt;210&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;apriori-tid&lt;/td&gt;
      &lt;td&gt;35&lt;/td&gt;
      &lt;td&gt;202&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;eclat&lt;/td&gt;
      &lt;td&gt;*&lt;/td&gt;
      &lt;td&gt;8000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;fp-growth&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;* Eclat generated long id lists and it depleted 8GB RAM very fast in my docker container, so I never ended this test.&lt;/p&gt;

&lt;h3 id=&quot;generated-rules&quot;&gt;Generated rules&lt;/h3&gt;
&lt;p&gt;All algorithms showed same 3 rules, with 2nd and 3rd beign the same pair.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;from-teimset&lt;/th&gt;
      &lt;th&gt;to_itemset&lt;/th&gt;
      &lt;th&gt;confidence&lt;/th&gt;
      &lt;th&gt;lift&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;22386&lt;/td&gt;
      &lt;td&gt;85099B&lt;/td&gt;
      &lt;td&gt;0.67&lt;/td&gt;
      &lt;td&gt;8.2&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22697&lt;/td&gt;
      &lt;td&gt;22699&lt;/td&gt;
      &lt;td&gt;0.74&lt;/td&gt;
      &lt;td&gt;17.1&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;22699&lt;/td&gt;
      &lt;td&gt;22697&lt;/td&gt;
      &lt;td&gt;0.7&lt;/td&gt;
      &lt;td&gt;17.1&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;22386 = JUMBO BAG PINK POLKADOT&lt;/p&gt;

&lt;p&gt;85099B = JUMBO BAG RED RETROSPOT&lt;/p&gt;

&lt;p&gt;22697 = GREEN REGENCY TEACUP AND SAUCER&lt;/p&gt;

&lt;p&gt;22699 = ROSES REGENCY TEACUP AND SAUCER&lt;/p&gt;

&lt;p&gt;Not very impressive findings, so it worth trying to experiment with different input parameters.
But based on them we can recommend someone buying “JUMBO BAG PINK POLKADOT” to get a “JUMBO BAG RED RETROSPOT” as well. Same goes for teacups.&lt;/p&gt;

&lt;h2 id=&quot;another-usages-of-frequent-pattern-mining&quot;&gt;Another usages of frequent pattern mining&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.300.4808&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Network traffic&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.ijeert.org/pdf/v3-i10/9.pdf&quot;&gt;Web pages&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/5662/e754f611c34c01e3126c3df63a4ce6e78cb3.pdf&quot;&gt;Image classification&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://academic.oup.com/bib/article/16/2/216/245744&quot;&gt;Bio informatics&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">Once novelty recommendation systems are used now by more and more e-commerce sites to help customers find products to purchase. For e-commerce business owners these tools facilitate cross-sales.</summary></entry></feed>