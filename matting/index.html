<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml"  lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1"/>

<script type="application/ld+json">
    {
        "@context" : "http://schema.org",
        "@type" : "BlogPosting",
        "mainEntityOfPage": {
             "@type": "WebPage",
             "@id": "https:\/\/smirnov-am.github.io"
        },
        "articleSection" : "post",
        "name" : "Rotoscoping with OpenCV\/C\x2b\x2b",
        "headline" : "Rotoscoping with OpenCV\/C\x2b\x2b",
        "description" : "How to replace background in a video using matting technique with C\x2b\x2b and OpenCV",
        "inLanguage" : "en-US",
        "author" : "",
        "creator" : "",
        "publisher": "",
        "accountablePerson" : "",
        "copyrightHolder" : "",
        "copyrightYear" : "2021",
        "datePublished": "2021-01-12 23:03:00 \x2b0000 UTC",
        "dateModified" : "2021-01-12 23:03:00 \x2b0000 UTC",
        "url" : "https:\/\/smirnov-am.github.io\/matting\/",
        "wordCount" : "1326",
        "keywords" : [ "VFX","OpenCV","C\x2b\x2b","Blog" ]
    }
    </script>

<title>Rotoscoping with OpenCV/C&#43;&#43; | Alexey Smirnov</title>

<meta property='og:title' content='Rotoscoping with OpenCV/C&#43;&#43; - Alexey Smirnov'>
<meta property='og:description' content='How to replace background in a video using matting technique with C&#43;&#43; and OpenCV'>
<meta property='og:url' content='https://smirnov-am.github.io/matting/'>
<meta property='og:site_name' content='Alexey Smirnov'>
<meta property='og:type' content='article'><meta property='og:image' content='https://www.gravatar.com/avatar/f3f61e69a3bdf7419f19cb1be356c0b1?s=256'><meta property='article:section' content='Post'><meta property='article:tag' content='VFX'><meta property='article:tag' content='OpenCV'><meta property='article:tag' content='C&#43;&#43;'><meta property='article:published_time' content='2021-01-12T23:03:00Z'/><meta property='article:modified_time' content='2021-01-12T23:03:00Z'/><meta name='twitter:card' content='summary'><meta name='twitter:site' content='@'><meta name='twitter:creator' content='@'>


<link href="https://smirnov-am.github.io/index.xml" rel="alternate" type="application/rss+xml" title="Alexey Smirnov" />

<link rel="stylesheet" href="https://smirnov-am.github.io/css/style.css"/><link rel="apple-touch-icon" sizes="180x180" href="https://smirnov-am.github.io/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://smirnov-am.github.io/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://smirnov-am.github.io/favicon-16x16.png">
<link rel="manifest" href="https://smirnov-am.github.io/site.webmanifest">
<link rel="mask-icon" href="https://smirnov-am.github.io/safari-pinned-tab.svg" color="#5bbad5">
<link rel="canonical" href="https://smirnov-am.github.io/matting/">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="theme-color" content="#ffffff">
<meta name="google-site-verification" content="LxHvTgaBdcBpIRtJMFKFiIvx5Mm45WC1z1S57O6O5O8" />
</head>
<body>
<section class="section">
  <div class="container">
    <nav id="nav-main" class="nav">
      <div id="nav-name" class="nav-left">
        <a id="nav-anchor" class="nav-item" href="https://smirnov-am.github.io">
          <h1 id="nav-heading" class="title is-4">Alexey Smirnov</h1>
        </a>
      </div>
      <div class="nav-right">
        <nav id="nav-items" class="nav-item level is-mobile"><a class="level-item" aria-label="github" href='https://github.com/smirnov-am'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
  
</svg></i>
            </span>
          </a><a class="level-item" aria-label="linkedin" href='https://linkedin.com/in/smirnovam'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path stroke-width="1.8" d="m5.839218,4.101561c0,1.211972 -0.974141,2.194011 -2.176459,2.194011s-2.176459,-0.982039 -2.176459,-2.194011c0,-1.211094 0.974141,-2.194011 2.176459,-2.194011s2.176459,0.982917 2.176459,2.194011zm0.017552,3.94922l-4.388022,0l0,14.04167l4.388022,0l0,-14.04167zm7.005038,0l-4.359939,0l0,14.04167l4.360816,0l0,-7.370999c0,-4.098413 5.291077,-4.433657 5.291077,0l0,7.370999l4.377491,0l0,-8.89101c0,-6.915523 -7.829986,-6.66365 -9.669445,-3.259423l0,-1.891237z"/>
  
</svg></i>
            </span>
          </a><a class="level-item" aria-label="youtube" href='https://youtube.com/channel/UC1PS5Vov2HSkz-fKCQUiffg'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M22.54 6.42a2.78 2.78 0 0 0-1.94-2C18.88 4 12 4 12 4s-6.88 0-8.6.46a2.78 2.78 0 0 0-1.94 2A29 29 0 0 0 1 11.75a29 29 0 0 0 .46 5.33A2.78 2.78 0 0 0 3.4 19c1.72.46 8.6.46 8.6.46s6.88 0 8.6-.46a2.78 2.78 0 0 0 1.94-2 29 29 0 0 0 .46-5.25 29 29 0 0 0-.46-5.33z"/>
  <polygon points="9.75 15.02 15.5 11.75 9.75 8.48 9.75 15.02"/>
  
</svg></i>
            </span>
          </a><a class="level-item" aria-label="email" href='mailto:msc.smirnov.am@gmail.com'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
  <polyline points="22,6 12,13 2,6"/>
  
</svg></i>
            </span>
          </a><a class="level-item" aria-label="rss" href='https://smirnov-am.github.io/index.xml'
            target='_blank' rel='noopener'>
            <span class="icon">
              <i class><svg viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle>
  
</svg></i>
            </span>
          </a></nav>
      </div>
    </nav>

    <nav class="nav">
      
      <div class="nav-left"><a class="nav-item" href="https://smirnov-am.github.io/tags/aws">
          <h2 class="title is-5">AWS</h2>
        </a><a class="nav-item" href="https://smirnov-am.github.io/tags/flask">
          <h2 class="title is-5">Flask</h2>
        </a><a class="nav-item" href="https://smirnov-am.github.io/tags/python">
          <h2 class="title is-5">Python</h2>
        </a><a class="nav-item" href="https://smirnov-am.github.io/tags/vfx">
          <h2 class="title is-5">Computer vision for VFX</h2>
        </a></div>
      

      
    </nav>

  </div>
  <script src="https://smirnov-am.github.io/js/navicon-shift.js"></script>
</section>
<section class="section" style="padding: 0px 0px;">
    <div class="container has-text-centered" >
      <a href="https://python.cards"><img src="https://smirnov-am.github.io/content/images/python-cards.png"></a>
    </div>>
</section>
<section class="section">
  <div class="container">
    <div class="subtitle tags is-6 is-pulled-right">
      
      
<a class="subtitle is-6" href="https://smirnov-am.github.io/tags/vfx">#VFX</a>



  
  | <a class="subtitle is-6" href="https://smirnov-am.github.io/tags/opencv">#OpenCV</a>
  
  | <a class="subtitle is-6" href="https://smirnov-am.github.io/tags/c&#43;&#43;">#C&#43;&#43;</a>
  

      
    </div>
    <h2 class="subtitle is-6">January 12, 2021</h2>
    <h1 class="title">Rotoscoping with OpenCV/C&#43;&#43;</h1>
    
    <div class="content">
      

<p>One of the most basic problems in VFX is separating an object in a video from its background. The object then composited back into new environment or scene. This task has different names such as matting, keying or more popular term rotoscoping.</p>

<p>In this demo you can see how a church in the foreground is separated from the background blue sky, which was later replaced with a sky full of stars. This is the kind of problem matting can help with.</p>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/psfRiN_H9FM" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<p>Full code and how to use it is in this repo <a href="https://github.com/smirnov-am/vfx/tree/main/matting" target="_blank">https://github.com/smirnov-am/vfx/tree/main/matting</a></p>

<h2 id="matting-problem">Matting problem</h2>

<p>Every pixel <code>\( I(x, y) \)</code> in a video frame can be expressed as a composition of <code>\( F(x, y) \)</code> - foreground pixel - and <code>\( B(x, y) \)</code> - background pixel - as:</p>

<div>$$
I(x, y) = \alpha(x, y) * F(x, y) + (1-\alpha(x, y)) * B(x, y) ~~~~ [1]
$$</div>

<p><code>\(\alpha\)</code> is a scalar in a range from 0 to 1 and <code>\(I\)</code>, <code>\(F\)</code> and <code>\(B\)</code> are vectors in RGB space, where each component represents an intensity of a respective color channel. This formula is referred to as matting equation.</p>

<p>It&rsquo;s impossible to solve this problem in general case as this system has only 3 equations - one for each color channel - but 7 unknowns. These unknowns are components of <code>\(F\)</code>, <code>\(B\)</code> and a scalar value of <code>\(\alpha\)</code>.</p>

<p>However, if <code>\(\alpha\)</code> is known, foreground and background can be derived:</p>

<div>$$
F = \alpha * I ~~~~ [2]
$$</div>

<div>$$
B = (1-\alpha) * I ~~~~ [3]
$$</div>

<p>But there is a way to supply additional information that can make this problem solvable and help with finding <code>\(\alpha\)</code>. Manually mark some pixels as foreground with white and, background with black like on this picture creating a trimap:</p>

<p><img src="https://smirnov-am.github.io/content/images/matting/trimap.gif" alt="trimap" /></p>

<p>I&rsquo;ve taken the first frame from my footage and using image editor roughly painted the church with white and sky with black brush.</p>

<p>There are two method how to solve matting equation [1] given such a trimap covered in this post:</p>

<ul>
<li>Bayes’ inference</li>
<li>artificial neural network</li>
</ul>

<h2 id="apply-bayes-theorem">Apply Bayes theorem</h2>

<p>Since the frame pixel <code>\(I\)</code> is something you already have as an input, what can be reasonable values for <code>\(F\)</code>, <code>\(B\)</code> and <code>\(\alpha\)</code> to produce such a frame? This question can be represented as the probability of these unknowns given <code>\(I\)</code>.</p>

<div>$$
P(F,B,\alpha|I)
$$</div>

<p>Now you need to find such unknowns - foreground <code>\( F \)</code>, background <code>\(B\)</code> and <code>\(\alpha\)</code> - for which this probability is maximum.</p>

<p>Bayes theorem can revert that conditional probability:</p>

<div>$$
P(F,B,\alpha|I) = \frac{P(I|F,B,\alpha)*P(F,B,\alpha)}{P(I)}
$$</div>

<p>The right part of this equation is a product of likelihood and prior probability, divided by evidence probability. Let’s tackle them separately.</p>

<p>The likelihood term in Bayes theorem reflects the knowledge of how likely is an image if foreground, background and <code>\(\alpha\)</code> are known. If they are known, <code>\(I\)</code> is directly computed using matting equation [1]. So you can model the likelihood PDF as a very narrow function with maximum where the matting equation is valid:</p>

<div>$$
P(I|F,B,\alpha) = e^{-\frac{1}{\sigma^2}*\left \| I - (\alpha*F + (1-\alpha)*B) \right \|}
$$</div>

<p>This PDF is a bell-shaped curve with the width controlled by <code>\(\sigma\)</code>, which is an input parameter for this method.</p>

<p>Prior term is a bit more difficult. First, the assumption that foreground, background and and <code>\(\alpha\)</code> are independent of each other breaks this term into 3:</p>

<div>$$
P(F,B,\alpha) = P(F) * P(B) * P(\alpha)
$$</div>

<p>Another useful assumption is that the probability distribution of <code>\(\alpha\)</code> is a constant. In reality is a beta-distribution with a lot of values close to extremes 0 and 1 and very few values in between.</p>

<p>As for PDFs of <code>\(F\)</code> and <code>\(B\)</code>, they can be modeled as Gaussian. Again in general case they are not, but in case of my footage the foreground is mainly brown and the background - sky - is blue. I’m going to put these assumptions to test later on.</p>

<p>Given that foreground and background PDFs are Gaussian, the probability of <code>\(F\)</code> and <code>\(B\)</code> in the prior term can be modeled as:</p>

<div>$$
P(B) = \frac{1}{2\pi^\frac{3}{2}|\Sigma |^\frac{1}{2}}exp(-\frac{1}{2}(B-\mu_B )^T\Sigma_B^{-1}(B-\mu_B))
$$</div>

<p>At last, the probability of evidence <code>\(P(I)\)</code> is a constant and is not relevant.</p>

<p>Given all these models and assumptions it&rsquo;s possible to just take a derivative and find the argument for which the conditional probability is at its maximum. This gives a closed form solution like:</p>

<div>$$
A \begin{bmatrix}F \\ B \end{bmatrix} = y ~~~~ [4]
$$</div>

<p>The exact elements of the matrices can be found in the code:</p>

<ul>
<li>6-by-6 <code>\(A\)</code> matrix for left hand side - <a href="https://github.com/smirnov-am/vfx/blob/f8bf01f625508f28620bd8c76536eb82ab2f8e6c/matting/bayes.cpp#L9" target="_blank">code</a></li>
<li>6-by-1 vector <code>\(y\)</code> for right hand side - <a href="https://github.com/smirnov-am/vfx/blob/f8bf01f625508f28620bd8c76536eb82ab2f8e6c/matting/bayes.cpp#L19" target="_blank">code</a></li>
</ul>

<p>Given that system of linear equations and a formula for <code>\(\alpha\)</code></p>

<div>$$
\alpha = \frac{(I-B)\cdot (F-B)}{(F-B)\cdot (F-B)} ~~~~ [5]
$$</div>

<p>it&rsquo;s possible to iteratively solve them until alpha is converged to some stable value.</p>

<h2 id="check-the-assumptions">Check the assumptions</h2>

<p>Now let’s test the assumption that PDF for foreground and background are Gaussian. Go thought the frame and trimap pixel by pixel at the same time and plot the pixels for which trimap value is either 0 or 1 in 3D RGB space:</p>

<p><img src="https://smirnov-am.github.io/content/images/matting/gauss.gif" alt="gauss" /></p>

<p>I&rsquo;ve done so with Python and pandas. I&rsquo;ve used plotly to visualize the distributions. Furthermore, I&rsquo;m not plotting all pixels as there are thousands of them, but just a fraction. But it&rsquo;s enough to see that foreground and background are nicely separated compact blobs:</p>

<h2 id="get-alpha-map-for-the-whole-video">Get alpha map for the whole video</h2>

<p>The trimap is created for the first frame of the video. Now there is an approximate alpha for each pixel in this first frame. It can be used in equation [4] to calculate foreground and background and use them to get more precise alpha using equation [5] until convergence to some stable number. So the alpha values calculated this way constitute a full alpha map for the first frame.</p>

<p>The alpha map for the first frame then used as a trimap for the second frame. Since there very little difference between the frames it speeds up calculations as the algorithm converges to stable values more quickly</p>

<p>But still in my case of Full HD 60fps footage which is 12s long it took hours. However, it has good potential for parallelization, I didn’t implement that, because got a more interesting idea.</p>

<p>The trimap provides a way to mark some pixels as 0 and another as 1 which looks like a perfect fit for a supervised learning algorithm, that can be implemented using OpenCV build-in artificial neural network.</p>

<h2 id="use-an-artificial-neural-network">Use an artificial neural network</h2>

<p>OpenCV has an implementation of multi-layer perceptron (MLP). To model foreground-background classification an input MLP layer is going to have 3 nodes - one for each color channel. The output layer has a single node for alpha. Since alpha can be fractional the output can be used as is.</p>

<p>All other hyper-parameters of the neural net should be tuned. For that you can train a network and produce an alpha map for the first frame. By comparing them visually you can select the best ones, just short-circuiting a standard approach of separating training set to train-test-validate batches.</p>

<p>The MLP topology looks like this:</p>

<p><img src="https://smirnov-am.github.io/content/images/matting/mlp.png" alt="mlp" /></p>

<p>Once the network is trained it is used to predict alpha for each pixel in each frame. The result again is a video alpha map.</p>

<p>This method works much faster compared to Bayes’ inference once the network is trained, but has a slow start since training and tuning the hyper-parameters takes some time.</p>

<h2 id="final-composition">Final composition</h2>

<p>Finally, given a video alpha map - a video consisting of alpha maps of individual frames of the original video - you can compose a new video by replacing the background with the new one using equations [2] and [3]</p>

<p>Here is a 30sec reel that shows the whole process:</p>


<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/9HJZA-fyR3Y" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>


<script>
MathJax = {
    tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$','$$'], ['\\[', '\\]']],
    processEscapes: true,
    processEnvironments: true
    },
    options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
    }
};

window.addEventListener('load', (event) => {
    document.querySelectorAll("mjx-container").forEach(function(x){
        x.parentElement.classList += 'has-jax'})
    });

</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script type="text/javascript" id="MathJax-script" async
src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>


      <section class="section">
  <p>Support the author - <a href="https://www.buymeacoffee.com/smirnovam">Buy me a coffee!</a></p>
</section>
    <script>talkyardServerUrl='https:\/\/comments-for-smirnov-am-github-io.talkyard.net';</script>
    <script async defer src="https://c1.ty-cdn.net/-/talkyard-comments.min.js"></script>
    
    <div class="talkyard-comments" data-discussion-id="matting" style="margin-top: 45px;">
    <noscript>Please enable Javascript to view comments.</noscript>
    <p style="margin-top: 25px; opacity: 0.9; font-size: 96%">Comments powered by
    <a href="https://www.talkyard.io">Talkyard</a>.</p>
    </div>

      
      <div class="related">

<h3>Similar articles:</h3>
<ul>
	
	<li><a href="https://smirnov-am.github.io/chromakeying/">Chroma Keying with OpenCV/C&#43;&#43;</a></li>
	
</ul>
</div>
      
    </div>
    
  </div>
</section>



<section class="section">
  <div class="container has-text-centered">
    <p>&copy; Alexey Smirnov 2021</p>
    
  </div>
</section>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-107429956-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>




</body>
</html>

