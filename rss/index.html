<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:media="http://search.yahoo.com/mrss/"><channel><title><![CDATA[smirnov-am.github.io]]></title><description><![CDATA[smirnov-am.github.io]]></description><link>https://smirnov-am.github.io/</link><image><url>https://smirnov-am.github.io/favicon.png</url><title>smirnov-am.github.io</title><link>https://smirnov-am.github.io/</link></image><generator>Ghost 2.21</generator><lastBuildDate>Wed, 23 Oct 2019 16:40:34 GMT</lastBuildDate><atom:link href="https://smirnov-am.github.io/rss/" rel="self" type="application/rss+xml"/><ttl>60</ttl><item><title><![CDATA[Run Flask on AWS ECS (Fargate)]]></title><description><![CDATA[<p>There is an alternative to run Flask on AWS Elastic Beanstalk that allow numerous customization options - is to run Flask on ECS Fargate. This serverless (you don't have to manage a cluster of EC2) solution runs Docker images and can run Flask web server.<br><br>There is a lot of</p>]]></description><link>https://smirnov-am.github.io/run-flask-on-aws-ecs/</link><guid isPermaLink="false">5db073431152ec0b4afd21d3</guid><category><![CDATA[Flask]]></category><category><![CDATA[AWS]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Wed, 23 Oct 2019 16:26:16 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/10/photo-1561475699-fa66c7246834.jpeg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/10/photo-1561475699-fa66c7246834.jpeg" alt="Run Flask on AWS ECS (Fargate)"><p>There is an alternative to run Flask on AWS Elastic Beanstalk that allow numerous customization options - is to run Flask on ECS Fargate. This serverless (you don't have to manage a cluster of EC2) solution runs Docker images and can run Flask web server.<br><br>There is a lot of AWS resources involved to make it work. I'm sharing CloudFormation templates that will create them automatically.<br><br><a href="https://github.com/smirnov-am/aws_ecs_flask">Source code</a></p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><p>Here are the details of these templates:</p><h2 id="resources">Resources</h2><p><code>flask_resources.yaml</code> - is a CloudFormation template that will create<br>services that won't change much. It consists of three parts.</p><h3 id="dns">DNS</h3><p><br>The input for that template is a domain name. I'm using <code>flask.com</code> as an example. <code>Route53::HostedZone</code> is created for that domain to host DNS records. It will also contain NS records to be used when you need to set up your domain registrar. <code>Route53::RecordSet</code> is a DNS A record then points <code>flask.com</code> to application load balancer (ALB).</p><h3 id="vpc">VPC</h3><p><br>A virtual private cloud (VPC) is a logical isolation of the resources.It's necessary for ALB to work. I'm following this <a href="https://docs.aws.amazon.com/codebuild/latest/userguide/cloudformation-vpc-template.html">example</a> that creates a pair of private subnets (where our containers will live), a pair of public subnets (different AZs) and all the wiring - routing tables and default routes, internet and NAT gateways.</p><h3 id="loadbalancer">LoadBalancer</h3><p><br>This one consists of a <code>ElasticLoadBalancingV2::LoadBalancer</code> that resides in 2 public subnets. There is one config parameter I have in the template, which is <code>idle_timeout.timeout_seconds</code>. More in it <a href="https://aws.amazon.com/blogs/aws/elb-idle-timeout-control/">here</a>.<br><br>LoadBalancer drive traffic to <code>ElasticLoadBalancingV2::Listener</code> which drives further to <code>ElasticLoadBalancingV2::TargetGroup</code>. There could be another additional listener for HTTPS. The listener is a very powerful thing. It can do SSL off-load and even Cognito authentication.<br><br> <code>ElasticLoadBalancingV2::TargetGroup</code> config will define how often it will call out Flask <code>health_check</code> endpoint to decide if the container is alive and available for accepting requests.</p><h3 id="ecs">ECS</h3><p><code>ECR::Repository</code> will hold Docker images. I'm building them locally, but it's also possible to use CodeBuild and have a full CI/CD pipeline for that (Maybe another post?)<br><code>ECS::Cluster</code> is a placeholder for the Flask stack.<br><code>flask_resources.yaml</code> stack export some variables to be used in <code>flask_stack.yaml</code>. The former will create a ECS task. I've tried to move as name resources to the first stack and leave only essentials in the second one.</p><h2 id="stack">Stack</h2><p><code>flask_stack.yaml</code> contains a <code>ECS::Service</code>. It run and maintains a number if running Docker containers (tasks) and associates load balancers with them.<br><br><code>ECS::TaskDefinition</code> is an instruction on how to run Docker container. Environment variables can be specified there as well as CPU and Memory that will be used by a task. See this <a href="https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-resource-ecs-taskdefinition.html#cfn-ecs-taskdefinition-memory">doc</a> for a reference.<br><br>TaskDefinition also specifies where to put stdout&amp;stderr logs. I'm putting them into Cloudwatch.<br><br>The inputs for that stack are CPU, Memory and tag. See <strong>Building image </strong>for tag.</p><h2 id="iam-roles">IAM roles</h2><p>There are a couple of roles created by both stacks:<br><strong> - TaskExecutionRole</strong> - a role that containers in this task can assume.  Its uses build in (managed) AmazonECSTaskExecutionRolePolicy<br><strong> - TaskRole</strong> - a role that grants containers in the task permission to call AWS APIs.<br> I've left a single policy that grants access to all DynamoDB tables. But of course, these policies should be as restrictive as possible (only necessary actions and resources/tables)<br><br>If Flask will be using RDS/Aurora, then these resources should be placed in the same VPC. There is no need for an additional role.</p><h2 id="enabling-ssl">Enabling SSL</h2><p>First, the certificate is needed:</p><!--kg-card-begin: markdown--><pre><code>Certificate:
    Type: &quot;AWS::CertificateManager::Certificate&quot;
    Properties:
      DomainName: !Sub &quot;*.${Domain}&quot;
      SubjectAlternativeNames:
        - !Ref Domain
</code></pre>
<!--kg-card-end: markdown--><p>Then this certificate is used by additional load balancer listener:</p><!--kg-card-begin: markdown--><pre><code>HTTPSListener:
Type: &quot;AWS::ElasticLoadBalancingV2::Listener&quot;
    Properties:
      Certificates:
        - CertificateArn: !Ref Certificate
      DefaultActions:
        - TargetGroupArn: !Ref TargetGroup
          Type: forward
      LoadBalancerArn: !Ref LoadBalancer
      Port: 443
      Protocol: HTTPS
</code></pre>
<!--kg-card-end: markdown--><p>Then a redirect should be added in <code>nginx.conf</code> inside a location<br>section:</p><!--kg-card-begin: markdown--><pre><code>if ($http_x_forwarded_proto != &quot;https&quot;) {
    rewrite ^(.*)$ https://$host$request_uri permanent;
}
</code></pre>
<!--kg-card-end: markdown--><h2 id="building-image">Building image<br></h2><p>I'm building a Docker image locally and pushing it to AWS ECR.<br><strong>1. </strong>Login to ERC <code>$(aws ecr get-login --region eu-west-1 --no-include-email)</code><br><strong>2. </strong>Build image locally <code>docker build . -t flask_image</code><br>See a folder <code>flask.com</code> in the repo.<br><strong>3. </strong>Get the image ID by issuing <code>docker images</code><br><strong>4. </strong>Tag image. For that you'll need you AWS account number and region.<br>Put the tag that will be passed to CF template.</p><p><code>docker tag &lt;image_id&gt; &lt;aws_account_number&gt;.dkr.ecr..amazonaws.com/:&lt;my_tag&gt;</code></p><p><strong>5. </strong>Upload the image <code>docker push &lt;aws_account_number&gt;.dkr.ecr.&lt;region&gt;.amazonaws.com/&lt;domain&gt;</code></p><h2 id="bringing-it-all-together">Bringing it all together</h2><p><strong>1. </strong>Create a stack from resources CloudFormation template<br><strong>2. </strong>Build and push the image to ECR<br><strong>3. </strong>Create a stack from stack.yaml CloudFormation template<br><strong>4. </strong>In Route53 locate a newly created hosted zone and find a A record with ALIAS. Open load balancer hostname in browser - you'll see a response from Flask<br><strong>5. </strong>Rewrite NS records in registrar to use the ones from the Hosted zone. (So example `flask.com` will lead to the deployed server)</p><h2 id="further-thoughts">Further thoughts</h2><p>The stacks are missing some important things:<br><strong>- </strong>Scaling. In <code>ECS::Service</code> a DesiredCount attribute can be specified to define the number of simultaneous running containers. But it doesn't change based on the load.<br><strong>- </strong>Alarms. There are logs on CloudWatch. An alarm can be created based on these logs, like a number of excessive 4XX, 5XX HTTP responses, to long load balancee response<br><strong>- </strong>CI/CD. Images are built locally, CodePipeline+CodeBuild can be used for that.<br><br></p>]]></content:encoded></item><item><title><![CDATA[Static website on AWS S3 with SSL and continuous delivery]]></title><description><![CDATA[<p>AWS S3 is perfect to host static websites. Basic setup when you have a CNAME DNS record pointing to the bucket endpoint covers a lot of use cases. Couple of things I'm missing is</p><ul><li>SSL</li><li>continuous delivery.</li></ul><p>For SSL we need CloudFront to serve as a global load balancer and</p>]]></description><link>https://smirnov-am.github.io/static-website-on-aws-s3-with-ssl-and-continuous-delivery/</link><guid isPermaLink="false">5d9363e2b7e01018b812d346</guid><category><![CDATA[AWS]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Tue, 01 Oct 2019 14:41:21 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/10/photo-1557944935-506efb8ba41d.jpeg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/10/photo-1557944935-506efb8ba41d.jpeg" alt="Static website on AWS S3 with SSL and continuous delivery"><p>AWS S3 is perfect to host static websites. Basic setup when you have a CNAME DNS record pointing to the bucket endpoint covers a lot of use cases. Couple of things I'm missing is</p><ul><li>SSL</li><li>continuous delivery.</li></ul><p>For SSL we need CloudFront to serve as a global load balancer and provide SSL offload.</p><p>To achieve continues delivery I'd like to connect the GitHub repo storing the source to CodePipeline. CodePipeline is triggered at every push to the master branch and automatically updates the content of the S3 bucket with changes source files.</p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="stack">Stack</h2><p>Let's first create a CloudFormation stack that will create</p><ul><li>S3 bucket - a regular bucket to store the files</li><li>BucketPolicy - to allow the read from the bucket</li><li>Route53 HostedZone - this is a placeholder for DNS records. Once created NS servers can be obtained from here. I'm registering domain names on GoDaddy, so I set NS servers there. It will also hold A record pointing to CloudFront</li><li>Route53 RecordSet - the A record pointing to CloudFront. It should refer to a CloudFront hosted zone (Z2FDTNDATAQYW2) as an alias target, not the one created above</li><li>SSLCert - the SSL certificate. It's free from AWS and when the stack is being created the owner of the AWS account should receive an email with a confirmation link</li><li>CloudFront Distribution - load balancer that binds it all together. It refers to SSL and drives traffic to S3</li></ul><h2 id="pipeline">Pipeline</h2><p>CodePipeline is ideal to deliver changes fast. In the case of static website, it's possible to just run <code>aws s3 sync</code> from the command line, but local changes might divert from the remote repo.</p><p>The pipeline creates a separate S3 bucket to store artifact - specifically the files it got from GitHub.<br>The pipeline itself consists of 2 steps:</p><ul><li>source - it will monitor changes in the master branch. For that to work an access token should be <a href="https://docs.aws.amazon.com/codepipeline/latest/userguide/GitHub-create-personal-token-CLI.html">created in GitHub</a></li><li>deploy - it will get the files from the artifact store and upload it to S3 hosting the website</li></ul><p>Cloudformation templates for stack and pipeline are available <a href="https://github.com/smirnov-am/s3_static_website_templates">here</a>. I'm<br>using the same stack for the landing of my pet project <a href="https://afplakkenonline.nl/">https://afplakkenonline.nl/</a></p>]]></content:encoded></item><item><title><![CDATA[Representing money in Python]]></title><description><![CDATA[<p>Python's <code>float</code> type is a natural first step to represent monetary amounts in the code. Almost all platforms map Python floats to IEEE-754 “double precision”.<br></p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><p>Doubles contain 53 bits of precision. When the machine is</p>]]></description><link>https://smirnov-am.github.io/representing-money-in-python/</link><guid isPermaLink="false">5d7e657311b503079d857dfe</guid><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Sun, 15 Sep 2019 16:30:10 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/09/alvaro-reyes-MEldcHumbu8-unsplash.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/09/alvaro-reyes-MEldcHumbu8-unsplash.jpg" alt="Representing money in Python"><p>Python's <code>float</code> type is a natural first step to represent monetary amounts in the code. Almost all platforms map Python floats to IEEE-754 “double precision”.<br></p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><p>Doubles contain 53 bits of precision. When the machine is trying to represent the fractional part (mantissa) of a given number it finds a bit sequence <code>b1, b2, .. b53</code> so that a sum: <code>b1*(0.5)^1 + b2*(0.5)^2 + .. +b53*(0.5)^53</code> is close to the number as possible. So, values such as 0.1 cannot be exactly represented.<br><br>Let's see how it can hinder money operations. A banana costs $1.01, I'm lowering the price to $0.99 and want to calculate lost revenue if I sell quintillion bananas (one with 18 zeros):</p><!--kg-card-begin: markdown--><pre><code class="language-python">format((1.01 - 0.99)*1e18, '.2f')
&gt;&gt;&gt;  '20000000000000016.00'
</code></pre>
<!--kg-card-end: markdown--><p>I expected a 2 with 16 zeros, but there are an additional 16 dollars. It will take a lot of time to sell so many bananas, but the calculation is wrong anyway.<br></p><p><strong>Integers</strong><br>One of the possible solutions is to use integer. So $1.01 is represented as 101, and<br>0.99 as 99 (simply multiplying everything by 100).</p><!--kg-card-begin: markdown--><pre><code class="language-python">format((101 - 99)*1e18 / 100, '.2f')
&gt;&gt;&gt; '20000000000000000.00'
</code></pre>
<!--kg-card-end: markdown--><p>It gives a correct answer, but it requires extra commitment from a developer to remember to convert the number coming to and from the application to the original format. Also, I don't still understand how to use it in the more complex operations.<br><br>Let's calculate an amount of money we get from a bank if we deposit $10000, with 15% annual rate compounded daily:</p><!--kg-card-begin: markdown--><pre><code class="language-python">deposit = 10000
deposit_internal = deposit * 100
future_value_internal = deposit_internal * (1 + (0.15/365))**365
future_value = future_value_internal/100
format(future_value, '.2f')
&gt;&gt;&gt; '11617.98'
</code></pre>
<!--kg-card-end: markdown--><p>Now let's use the preferred way to represent exact fractional amounts:<br><br><strong>Decimal</strong><br>It's a part of a standard library and provides a representation of real numbers.<br>Interestingly that if I use Decimal in the deposit example from the above, I'll get a slightly different result:</p><!--kg-card-begin: markdown--><pre><code class="language-python">from decimal import Decimal, getcontext
deposit = Decimal('10000')
future_value = deposit * (1 + (Decimal('0.15')/Decimal('365')))**Decimal('365')
future_value
&gt;&gt;&gt; Decimal('11618.16')
</code></pre>
<!--kg-card-end: markdown--><p>Yay! Additional 18 cents.<br><br><strong>Performance</strong><br>Float is not that bad. In most of the cases, it's precision is more than enough. It also appears more fast than Decimal:</p><!--kg-card-begin: markdown--><pre><code>In [2]: def float_order(item_price, item_count):
   ...:     return sum([item_price for _ in range(item_count)])
   ...:

In [3]: def decimal_order(item_price, item_count):
   ...:     decimal_item_price = Decimal(item_price)
   ...:     return sum([decimal_item_price for _ in range(item_count)])
   ...:

In [4]: %timeit float_order(1.01, 10000)
297 µs ± 11.6 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)

In [5]: from decimal import Decimal

In [6]: %timeit decimal_order('1.01', 10000)
783 µs ± 19.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)
</code></pre>
<!--kg-card-end: markdown--><p>Have you ever experiences problems when working with monetary values represented by <code>float</code>? Connect with me on <a href="https://www.linkedin.com/in/smirnovam">LinkedIn</a></p>]]></content:encoded></item><item><title><![CDATA[CI/CD  pipeline for AWS Lambda (Python runtime)]]></title><description><![CDATA[<p>Continuous integration and continuous delivery are powerful practices that allow release software faster and of a higher quality. I'm going to walk through steps to implement CI/CD pipeline for a small lambda function that calculates square roots by:</p><ul><li>getting message from SQS that contains the number to calculate sqrt</li></ul>]]></description><link>https://smirnov-am.github.io/ci-ci-pipeline-for-aws-lambda-python-runtime/</link><guid isPermaLink="false">5d57ecbe2c52c2026cb2bc94</guid><category><![CDATA[AWS]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Sun, 18 Aug 2019 14:05:36 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/08/quinten-de-graaf-L4gN0aeaPY4-unsplash.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/08/quinten-de-graaf-L4gN0aeaPY4-unsplash.jpg" alt="CI/CD  pipeline for AWS Lambda (Python runtime)"><p>Continuous integration and continuous delivery are powerful practices that allow release software faster and of a higher quality. I'm going to walk through steps to implement CI/CD pipeline for a small lambda function that calculates square roots by:</p><ul><li>getting message from SQS that contains the number to calculate sqrt for</li><li>checks if the calculation was done before by querying DynamoDB</li><li>if there is not cached answer in DynamoDB - calculate sqrt and saves the result</li><li>print the result so it's visible in CloudWatch logs</li></ul><p>Things I'd like the pipeline to do:</p><ul><li>create all the resources - SQS and Dynamo</li><li>subscribe to any changes that are committed to master branch of GitHub repo</li><li>run tests- I'm going to run unit tests, but since the resources are there you can run integration/end-to-end tests</li><li>build the package for lambda with all python dependencies</li><li>deploy the package</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><p>Pipeline architecture:<br></p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/08/cicd_lambda.png" class="kg-image" alt="CI/CD  pipeline for AWS Lambda (Python runtime)"></figure><!--kg-card-end: image--><p>The initial CloudFormation template along with all the code can be found in <a href="https://github.com/smirnov-am/cicd_lambda">this GitHub repo</a></p><p>I'm going to walk through the details of this pipeline.</p><p>The <code>pipeline.yaml</code> (see <code>aws</code> folder in the repo) contain the CloudFormation template that will create SQS, Dynamo, CodePipeline with all its steps:</p><ul><li>source step to get the source code form GitHub</li><li>CodeTest (CodeBuild type) to run a container inside which I'm running tests</li><li>CodeBuild - a container that will prepare the build - zip file on S3 Lambda can digest</li><li>CodeDeploy - the step to deploy newly build Lambda.</li></ul><p>The first thing to do is to create GitHub OAuth token - just follow steps 1-6 from <a href="https://docs.aws.amazon.com/en_us/codepipeline/latest/userguide/GitHub-create-personal-token-CLI.html">this AWS doc</a>.</p><p>Next, you need to create a stack from AWS console - Go to CloudFormation and click Create Stack. It will ask to fill in the stack parameters:</p><ul><li>name - a reference to the resources of the stack</li><li>GitHub token, repo owner and repo name</li></ul><p>After it's created you can go to CodePipeline to see the newly created pipeline. If you open it there will be Source, CodeTest, CodeBuild and CodeDeploy stages present.</p><p>Also, all additional resources will be created:</p><ul><li>SQS queue that will feed the Lambda</li><li>DynamoDB table with Pay-Per-Request billing</li><li>S3 bucket for pipeline artifacts - it's the mechanism to pass result of CodePipeline stages between each other</li><li>S3 bucket that will hold zip file with packaged Lambda code</li></ul><p>Source step of the pipeline is pretty autonomous. AWS will monitor the changes and start the execution of the pipeline once there was a push to the master branch. There is a limit on how many repositories it can monitor so the alternative is to implement a GitHub webhook that will trigger a special Lambda that in turn will start pipeline execution.</p><p>CodeTest is a step of CodeBuild type. Here I'd like to run available tests for the code. Usually, the unit tests are run by developers individually by implementing pre-commit hooks on the local machine. But this step ensures that they were executed before push. Also, it can run the test for a higher level of the testing pyramid.</p><p>CodeBuild uses <a href="https://chalice.readthedocs.io/en/latest/">chalice</a> package to do a couple of things</p><ul><li>create CloudFormation template to deploy lambda</li><li>package Lambda code</li><li>create Lambda policies</li></ul><p>The important part of this stage is the image the container will use. Since some python packages are wrappers around C libraries, which are compiled when we run <code>pip install</code>, so the OS where we run <code>pip install</code> should be similar to the OS which will run the code and use these packages. I found this images <code>amazonlinux:latest</code> on DockerHub, which resembles Lambda runtime. In the container I'm creating a virtual environment and install every dependency in it. Then I just copy site-packages to <code>vendor</code> folder.</p><!--kg-card-begin: markdown--><pre><code>- python3 -m venv v-env &amp;&amp; . v-env/bin/activate &amp;&amp; pip install --upgrade pip &amp;&amp; pip install -r requirements/requirements.txt &amp;&amp; deactivate
- mkdir vendor
- cp -R v-env/lib/python3.7/site-packages/. vendor
- cp -R v-env/lib64/python3.7/site-packages/. vendor
</code></pre>
<!--kg-card-end: markdown--><p>Next thing is our code - it should be placed in a <code>vendor</code> folder as well as per chalice docs. I don't like to have it in my projects structures so I'm creating it in <code>codebuild.yaml</code> (which is referred in CodeTest as a <code>buildspec</code> - a script to run) and copying everything in it.</p><!--kg-card-begin: markdown--><pre><code>- cp -R my_package vendor
</code></pre>
<!--kg-card-end: markdown--><p>There is another difficulty - a Lambda IAM policy. Ideally, it should be as restrictive as possible, but grant access to the SQS and Dynamo we already created. In this stage I'm passing a number of different environment variables to the container:</p><ul><li>the ones that start with <code>LAMBDA_ENV</code> will be put into Lambda config to be available at its runtime</li><li>the ones starting with <code>POLICY_ENV</code> will be used to generate policy document (chalice policy generator is not yet good enough for that)</li></ul><p>There is a <code>config_generator.py</code> script that will read these variables and put them in proper places. <code>LAMBDA_ENV</code> will be put into a file  <code>.chalice/config.json</code> and <code>POLICY_ENV</code>  will go to <code>.chalice/police.json</code> - both will be used later by chalice to generate CloudFormation</p><p>Finally, the size of the build should be less than 265Mb. So I'm deleting extra files (<code>boto3</code> is needed for build, but it's available in Lambda runtime so no need to take it with us).</p><!--kg-card-begin: markdown--><pre><code>- echo 'Size of build' $(du -sm --exclude=./v-env .) 'MB'
- find . -name &quot;*.pyc&quot; -exec rm -f {} \;
- find ./vendor  -name 'boto3' -prune -type d -exec rm -rf {} \;
- find ./vendor  -name 'botocore' -prune -type d -exec rm -rf {} \;
- echo 'Size of build after cleaning' $(du -sm --exclude=./v-env .) 'MB'
</code></pre>
<!--kg-card-end: markdown--><p>The <code>chalice package</code> command, in the end, will create a zip file along with <code>sam.json</code> file. AWS CLI command will prepare the final template for CloudFormation - <code>transformed.yaml</code> - that will drive the deploy stage</p><!--kg-card-begin: markdown--><pre><code>- . v-env/bin/activate &amp;&amp; python config_generator.py &amp;&amp; chalice package /tmp/packaged &amp;&amp; deactivate
- aws cloudformation package --template-file /tmp/packaged/sam.json --s3-bucket ${APP_S3_BUCKET} --output-template-file transformed.yaml
</code></pre>
<!--kg-card-end: markdown--><p>After all that all the changes to the master branch of your repo should be automatically tested, (ideally) integrated and deployed. </p><p>If you use Python in a serverless environment on AWS or use CI/CD for such applications, connect with me on <a href="https://www.linkedin.com/in/smirnovam/">LinkedIn</a></p><p>Code for this post is available <a href="https://github.com/smirnov-am/cicd_lambda">here</a></p>]]></content:encoded></item><item><title><![CDATA[Anomalies in bank transactions]]></title><description><![CDATA[<p>Recently I've noticed suspicious transactions in my history that were initiated by some shady company that provides as the put it "opportunity to shop with discount" for their subscribers. Some web-shop had small font checkbox that initiated this subscription. Looks like the whole business model of such companies based on</p>]]></description><link>https://smirnov-am.github.io/anomalies-in-bank-transactions/</link><guid isPermaLink="false">5d4ab3c12c52c2026cb2bbe1</guid><category><![CDATA[machine learning]]></category><category><![CDATA[python]]></category><category><![CDATA[Security]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Wed, 07 Aug 2019 19:03:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/08/hand-keyboard-secured-34203.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/08/hand-keyboard-secured-34203.jpg" alt="Anomalies in bank transactions"><p>Recently I've noticed suspicious transactions in my history that were initiated by some shady company that provides as the put it "opportunity to shop with discount" for their subscribers. Some web-shop had small font checkbox that initiated this subscription. Looks like the whole business model of such companies based on people who don't check their transaction histories often. Needless to say, there were no subscription confirmation email, monthly bill or - most importantly - discounts I was supposed to receive.</p><p>After that, I decided to investigate methods to detect suspicious transactions. Of course, banks do that themselves and I'm not supposed to see any in my history. Anyway, I'll cover Low-pass filter, Benford's law, SVM, LOF and IsolationForest.</p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="input-data">Input data</h2><p>I'm using one of the largest banks in the Netherlands - ABN AMRO. I was able to download transaction history from their online banking platform in Excel format - very nice of them.<br>First of all transaction history contains credits - no need to take them into account. Debits are negative in history, so I convert them to positive numbers.</p><p>The tricky part is a date. There are <code>transactiondate</code> and <code>valuedate</code> columns in history. Also, some transactions have date and time in their description. It may come handy when I'll be doing feature engineering for machine learning. For now, I'll just extract date from <code>transactiondate</code> column  with <code>python-dateutil</code><br>parser. Here is the code to converting export from online banking to the usable dataframe</p><!--kg-card-begin: markdown--><pre><code class="language-python">import pandas as pd
from dateutil.parser import parse

df = pd.read_excel('/home/as/Desktop/abn.xls')
df['date'] = df['transactiondate'].apply(lambda x: parse(str(x)))
df.drop(['accountNumber', 'mutationcode', 'transactiondate',
         'valuedate', 'startsaldo', 'endsaldo'], axis=1, inplace=True)
df['amount'] = df['amount'].apply(abs)
df.set_index('date', inplace=True)
df.head()
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th style="text-align:left">date</th>
<th style="text-align:right">amount</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">10</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">27.2</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">19.04</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">36.17</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">5.4</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><h2 id="low-pass-filter">Low-pass filter</h2><p>Now I have a time-series - amount vs date. Applying moving average to is effectively is a low-pass filter that smoothes the series. I've decided to try windows of 7 and 30 days. This running average is not constant and has a standard deviation. And the idea behind this method is to find transactions that more than N standard deviation away from the smoothed line (let N=2).</p><!--kg-card-begin: markdown--><pre><code class="language-python">df['avg_7d'] = df['amount'].rolling('7D').mean()
df['avg_30d'] = df['amount'].rolling('30D').mean()

df['resudual_avg_7d'] = df['amount'] - df['avg_7d']
df['resudual_avg_30d'] = df['amount'] - df['avg_30d']

std_7d = df['resudual_avg_7d'].std()
std_30d = df['resudual_avg_30d'].std()

df['outlier_7d'] = df.apply(lambda row: row['amount'] if abs(row['resudual_avg_7d']) &gt; 2*std_7d else None, axis=1)
df['outlier_30d'] = df.apply(lambda row: row['amount'] if abs(row['resudual_avg_30d']) &gt; 2*std_30d else None, axis=1)
</code></pre>
<!--kg-card-end: markdown--><p>Looks like outliers based on 7D moving average are the same as for 30D window</p><!--kg-card-begin: markdown--><pre><code class="language-python">all((df[(df.outlier_30d &gt; 0) &amp; (df.outlier_7d &gt; 0)]).index == (df[df.outlier_30d &gt; 0]).index)
</code></pre>
<!--kg-card-end: markdown--><p>Let's visualize the time-series and the result. I'm using a log scale because the amounts have order magnitude difference</p><!--kg-card-begin: markdown--><pre><code class="language-python">import plotly
import plotly.graph_objs as go

plotly.offline.init_notebook_mode(connected=True)

data = [go.Scatter(x=df.index, y=df.amount, name='amount', mode = 'markers', marker={'size': 2}),
        go.Scatter(x=df.index, y=df.avg_7d, name='avg 7D'),
        go.Scatter(x=df.index, y=df.avg_30d, name='avg 30D'),
        go.Scatter(x=df.index, y=df.outlier_7d,
                   name='outliers 7D',
                   mode = 'markers',
                   marker = dict(size = 5,
                                 color = 'rgba(152, 0, 0, .8)',
                                 line = dict(width = 2,
                                             color = 'rgb(0, 0, 0)')),
                   text=df.description)]
layout = go.Layout(
    xaxis=dict(
        autorange=True
    ),
    yaxis=dict(
        type='log',
        autorange=True
    )
)
fig = go.Figure(data=data, layout=layout)
plotly.offline.iplot(fig)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/08/averages.png" class="kg-image" alt="Anomalies in bank transactions"></figure><!--kg-card-end: image--><p>The big red dots show the outliers. They are:</p><p><strong>- </strong>big purchases I've made</p><p><strong>- </strong>rent</p><p><strong>- </strong>1EUR chocolate bars from a wending machine during the week I've spent 10K</p><p>Not much, but at least I've learned how to use <code>plotly</code> here.</p><h2 id="benford-s-law">Benford's law</h2><blockquote>In the 2016 movie The Accountant, Ben Affleck’s character uses Benford’s Law to expose the theft of funds from a robotics company.</blockquote><p>According to that law, a leading significant digit in a series of naturally occurring numbers is likely to be small. There distribution of the first digits in a series of number can be described with a known <a href="https://wikimedia.org/api/rest_v1/media/math/render/svg/26461e7841d135d327aa7d0f914236862e890e7b">formula</a>.</p><p>First I'm going to multiply an amount column by 100, so purchases less than a euro will also participate in the party. Then I'm creating a column with just the first digit of the amount</p><!--kg-card-begin: markdown--><pre><code>df['amount'] = df['amount'].apply(lambda x: 100*x)
df['first_digit'] = df['amount'].apply(lambda x: str(x)[0])
</code></pre>
<!--kg-card-end: markdown--><p>Then I use <code>numpy</code> to get a histogram of the first digits to plot against known distribution.</p><!--kg-card-begin: markdown--><pre><code>import numpy as np
bins = [1,2,3,4,5,6,7,8,9]
count, division = np.histogram(df[&quot;first_digit&quot;], bins=bins, density=True)
</code></pre>
<!--kg-card-end: markdown--><p>The Benford's law distribution</p><!--kg-card-begin: markdown--><pre><code>from math import log10
benford = [log10(1 + 1/d) for d in bins]
</code></pre>
<!--kg-card-end: markdown--><p>Now the visualization:</p><!--kg-card-begin: markdown--><pre><code>data = [go.Bar(x=bins, y=count, name='amount'),
        go.Scatter(x=bins, y=benford, name='Benford law')]
layout = go.Layout(
    xaxis=dict(
        autorange=True
    ),
    yaxis=dict(

        autorange=True
    )
)
fig = go.Figure(data=data, layout=layout)
plotly.offline.iplot(fig)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/08/benfords.png" class="kg-image" alt="Anomalies in bank transactions"></figure><!--kg-card-end: image--><p>The actual distribution is more or less follows that law. More transactions are starting with 8 and 1. And less starting with 4 and 9. According to Wiki:</p><blockquote>Distributions that would not be expected to obey Benford's Law ... : Where numbers are influenced by human thought: e.g. prices set by psychological thresholds ($1.99)</blockquote><p>Also from this analysis, it's not obvious how to extract suspicious transactions.</p><h2 id="machine-learning-approaches">Machine learning approaches</h2><p>There are a couple of algorithms implemented in <a href="https://scikit-learn.org/0.20/auto_examples/plot_anomaly_comparison.html">scikit-learn</a> for anomaly detection. All of them expect to have a list of samples in some feature space. The above data frame has date column with is not a good feature - it's difficult to use it as a coordinate and calculate distances with it. But it can be used to generate features:</p><p><strong>- </strong>day of the month</p><p><strong>- </strong>day of the week</p><p><strong>- </strong>week of the month (which is just a linear transformation from the day of the month)</p><p>There are also lagging features that can be formed from the amounts:</p><p><strong>- </strong>average of the last X days</p><p><strong>- </strong>value of the amount on T-1 (skip for simplicity)</p><p>So the feature engineering looks like this:</p><!--kg-card-begin: markdown--><pre><code>df['weekday'] = df.apply(lambda row: row.name.weekday(), axis=1)
df['day'] = df.apply(lambda row: row.name.day,  axis=1)
df['prev_amount'] = df['amount'].shift(1)
df.dropna(inplace=True)
</code></pre>
<!--kg-card-end: markdown--><p>The resulted training set:</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th style="text-align:left">date</th>
<th style="text-align:right">amount</th>
<th style="text-align:right">avg_30d</th>
<th style="text-align:right">weekday</th>
<th style="text-align:right">day</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">10</td>
<td style="text-align:right">10</td>
<td style="text-align:right">5</td>
<td style="text-align:right">9</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">27.2</td>
<td style="text-align:right">18.6</td>
<td style="text-align:right">5</td>
<td style="text-align:right">9</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">19.04</td>
<td style="text-align:right">18.7467</td>
<td style="text-align:right">5</td>
<td style="text-align:right">9</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">36.17</td>
<td style="text-align:right">23.1025</td>
<td style="text-align:right">5</td>
<td style="text-align:right">9</td>
</tr>
<tr>
<td style="text-align:left">2018-06-09 00:00:00</td>
<td style="text-align:right">5.4</td>
<td style="text-align:right">19.562</td>
<td style="text-align:right">5</td>
<td style="text-align:right">9</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>And as for the most ML algorithms the samples should be scaled to have zero mean, unit variance. But since the samples are having anomalies:</p><blockquote>If your data contains many outliers, scaling using the mean and variance of the data is likely to not work very well. In these cases, you can use <code>robust_scale</code></blockquote><!--kg-card-begin: markdown--><pre><code>from sklearn import preprocessing
X = df[['amount', 'avg_30d', 'weekday', 'day']].values
X = preprocessing.robust_scale(X)
</code></pre>
<!--kg-card-end: markdown--><h2 id="svm">SVM</h2><p>Usually, SVM is used for classification in supervised learning - that is when there is labeled data. SVM finds a hyperplane that acts as a border between classes. There is one algorithm that can be used on unlabelled data - One Class SVM. It finds the smallest hypersphere that the samples allowing for some outliers. The idea is to find a function that is positive for regions with a high density of points, and negative for small densities.<br>One of the hyperparameters of the <code>scikit-learn</code> implementation is <code>nu</code> - the fraction of outliers to expect. I'm putting 5%, but when I've tried default 50% half of the transactions were marked as an outlier.</p><!--kg-card-begin: markdown--><pre><code>from sklearn import svm
outliers_fraction = 0.05
clf = svm.OneClassSVM(nu=outliers_fraction, kernel=&quot;rbf&quot;)
y_pred_outliers = clf.fit_predict(X)
df['outlier_svm'] = y_pred_outliers == -1
</code></pre>
<!--kg-card-end: markdown--><h2 id="lof">LOF</h2><p>Scikit-learn has a clear explanation of the algorithm:</p><blockquote>The anomaly score of each sample is called Local Outlier Factor. It measures the local deviation of density of a given sample with respect to its neighbors. It is local in that the anomaly score depends on how isolated the object is with respect to the surrounding neighborhood. More precisely, locality is given by k-nearest neighbors, whose distance is used to estimate the local density. By comparing the local density of a sample to the local densities of its neighbors, one can identify samples that have a substantially lower density than their neighbors. These are considered outliers.</blockquote><p>The algorithm also except a hyperparameter of how many outliers to detect.</p><!--kg-card-begin: markdown--><pre><code>from sklearn.neighbors import LocalOutlierFactor

clf_lof = LocalOutlierFactor(contamination=outliers_fraction)
y_pred_outliers_lof = clf_lof.fit_predict(X)
df['outlier_lof'] = y_pred_outliers_lof == -1
</code></pre>
<!--kg-card-end: markdown--><h2 id="ensemble">Ensemble</h2><p>The one from ensemble learning algorithms is IsolationForest</p><blockquote>The IsolationForest ‘isolates’ observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.<br>Since recursive partitioning can be represented by a tree structure, the number of splittings required to isolate a sample is equivalent to the path length from the root node to the terminating node.<br>This path length, averaged over a forest of such random trees, is a measure of normality and our decision function.<br>Random partitioning produces noticeably shorter paths for anomalies. Hence, when a forest of random trees collectively produce shorter path lengths for particular samples, they are highly likely to be anomalies.</blockquote><!--kg-card-begin: markdown--><pre><code>from sklearn.ensemble import IsolationForest

clf_forest = IsolationForest(behaviour=&quot;new&quot;, contamination=outliers_fraction)
y_pred_outliers_forest = clf_forest.fit_predict(X)
df['outlier_forest'] = y_pred_outliers_forest == -1
</code></pre>
<!--kg-card-end: markdown--><h2 id="results">Results</h2><p>One way to display the result is just to show it in time-series:</p><!--kg-card-begin: markdown--><pre><code class="language-python">outliers_svm = df.loc[df['outlier_svm'], ['amount']]
outliers_lof = df.loc[df['outlier_lof'], ['amount']]
outliers_forest = df.loc[df['outlier_forest'], ['amount']]
data = [go.Scatter(x=df.index,
                   y=df.amount,
                   name='amount',
                   mode = 'markers',
                   marker={'size': 2}),
        go.Scatter(x=outliers_svm.index,
                   y=outliers_svm.amount,
                   name='outliers svm',
                   mode = 'markers',
                   marker = dict(size = 5)),
        go.Scatter(x=outliers_lof.index, y=outliers_lof.amount,
                   name='outliers lof',
                   mode = 'markers',
                   marker = dict(symbol=&quot;cross&quot;, size = 5)),
        go.Scatter(x=outliers_forest.index, y=outliers_forest.amount,
                   name='outliers forest',
                   mode = 'markers',
                   marker = dict(symbol=&quot;square-cross&quot;, size = 5, color='red'))
       ]

layout = go.Layout(
    xaxis=dict(
        autorange=True
    ),
    yaxis=dict(
        type='log',
        autorange=True
    )
)
fig = go.Figure(data=data, layout=layout)
plotly.offline.iplot(fig)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/08/res_t.png" class="kg-image" alt="Anomalies in bank transactions"></figure><!--kg-card-end: image--><p>Another one is to apply dimensionality reduction and plot in simple 2D<br>(maybe it makes sense to do PCA before running classification?)</p><!--kg-card-begin: markdown--><pre><code class="language-python">from sklearn.decomposition import PCA
pca = PCA(n_components=2)
X_two_dim = pca.fit_transform(X)

df2 = pd.DataFrame(X_two_dim, columns=['x', 'y'], index=df.index)
df2['outlier_svm'] = df.outlier_svm
df2['outlier_lof'] = df.outlier_lof
df2['outlier_forest'] = df.outlier_forest

data = [go.Scatter(x=df2.x, y=df2.y, name='amount', mode = 'markers', marker={'size': 2}),
        go.Scatter(x=df2[df2.outlier_svm == 1].x, y=df2[df2.outlier_svm == 1].y, name='outlier_svm', mode = 'markers', marker={'size': 5}),
        go.Scatter(x=df2[df2.outlier_lof == 1].x, y=df2[df2.outlier_lof == 1].y, name='outlier_lof', mode = 'markers', marker={'size': 5}),
        go.Scatter(x=df2[df2.outlier_forest == 1].x, y=df2[df2.outlier_forest == 1].y, name='outlier_forest', mode = 'markers', marker={'size': 5}),
       ]

layout = go.Layout(
    xaxis=dict(
                type='log',
        autorange=True
    ),
    yaxis=dict(

        autorange=True
    )
)
fig = go.Figure(data=data, layout=layout)
plotly.offline.iplot(fig)
</code></pre>
<!--kg-card-end: markdown--><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/08/newplot.png" class="kg-image" alt="Anomalies in bank transactions"></figure><!--kg-card-end: image--><p>Of course, these algorithms are not an end-to-end solution for fraud detection in bank transactions. There are much more signals that can be used</p><p><strong>- </strong>whether a transaction was done from a terminal or online bank</p><p><strong>- </strong>if the recipient of the transaction a known account</p><p><strong>- </strong>where was the transaction was made - in or outside of  the country</p><p>Also, they failed to find the transactions from the introduction to this post. But to solve that problem I'm building an <a href="https://afplakkenonline.nl/">app</a>. </p>]]></content:encoded></item><item><title><![CDATA[Calculating enterprise value with Python and Pandas (part 2). WACC and DCF]]></title><description><![CDATA[<p>The weighted average cost of capital (WACC) is used as the discount rate for a firm’s anticipated free cash flows (FCFs)<br><br>The formula is the following:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/07/wacc_formula.png" class="kg-image"></figure><!--kg-card-end: image--><p>where<br>E = market value of the firm’s equity <br>D = market value of the firm’s debt<br>Tc = firm’s corporate tax rate<br></p>]]></description><link>https://smirnov-am.github.io/calculating-enterprise-value-with-python-and-pandas-part-1-wacc-and-dcf/</link><guid isPermaLink="false">5d1e67ba2c52c2026cb2bb22</guid><category><![CDATA[Financial Modelling]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Sun, 07 Jul 2019 09:01:04 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/07/phyton-i-reka.png" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/07/phyton-i-reka.png" alt="Calculating enterprise value with Python and Pandas (part 2). WACC and DCF"><p>The weighted average cost of capital (WACC) is used as the discount rate for a firm’s anticipated free cash flows (FCFs)<br><br>The formula is the following:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/07/wacc_formula.png" class="kg-image" alt="Calculating enterprise value with Python and Pandas (part 2). WACC and DCF"></figure><!--kg-card-end: image--><p>where<br>E = market value of the firm’s equity <br>D = market value of the firm’s debt<br>Tc = firm’s corporate tax rate<br>rE = firm’s cost of equity<br>rD = firm’s cost of debt</p><p>There are some difficulties in calculating certain parts:<br><br><strong>1. </strong>Firm’s cost of equity rE has two approaches to it: Gordon model and capital asset pricing model (CAPM).</p><ul><li>The Gordon model calculates the cost of equity based on the anticipated cash flows paid to the shareholders of the firm</li><li>The capital asset pricing model (CAPM) uses the correlation between firm's equity return and a broad market portfolio. </li></ul><p><strong>2. </strong>Cost of debt rD, the anticipated future cost of the firm’s borrowing.</p><ul><li>The cost of debt rD is computed  dividing current net interest<br>payments by average net debt</li><li>Alternatively, it can be obtained from an yield curve</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h3 id="equity-e">Equity, E</h3><p><br>For a public company E equals its market cap:</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.yahoo_finance import YahooFinanceParser
parser = YahooFinanceParser('AAPL')
parser.get_value('Market Cap')
</code></pre>
<!--kg-card-end: markdown--><h3 id="debt-d">Debt, D</h3><p>A common approximation for this number  is to take the balance sheet value of the <strong>firm’s debt </strong>minus the value of the <strong>firm’s cash balances </strong>minus the value of its<br><strong>marketable securities</strong>.</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.wacc import get_debt
parser = YahooFinanceParser('AAPL')
df = parser.get_dataframe('balance-sheet')
get_debt(df)
</code></pre>
<!--kg-card-end: markdown--><h3 id="tax-rate">Tax Rate</h3><p>The <strong>Income tax expense </strong>and <strong>Income before taxes </strong>can be found in the income statement. The tax rate is equal to the quotient of the two:</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.wacc import get_tax_rate
parser = YahooFinanceParser('AAPL')
df = parser.get_dataframe('income-statement')
get_tax_rate(df)
</code></pre>
<!--kg-card-end: markdown--><h3 id="cost-of-debt">Cost of Debt</h3><p>I'll cover basic calculation which uses  interest paid value from the income statement (called Interest Expense in Yahoo Finance, if I'm not mistaken) and net debt taken from the balance sheet. In contrast to debt value from the previous section this one subtract cash and short term investments from the sum of short- and long-term debt.<br><br>To get cost of debt a current year's paid interest is divided by average net debt from this and previous year.</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.wacc import get_cost_of_debt
balance_sheet = parser.get_dataframe('balance-sheet')
income_statement = parser.get_dataframe('income-statement')
get_cost_of_debt(balance_sheet, income_statement)
</code></pre>
<!--kg-card-end: markdown--><p>Another approach is to get an yield of bonds issues by other companies that have the same rating (Fitch, S&amp;P), treat yield as a function of time to maturity of the bond. Then the firm's debt is assumed to have a certain time to maturity as well. The cost of debt can be obtained by applying regression to this function.</p><h3 id="cost-of-equity">Cost of equity</h3><p>The most widely used approach is the CAMP model. The classic CAPM formula uses a security market line (SML) equation that ignores taxes:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/07/latex_aa96e3d999012febe6c09b8437564a0f.png" class="kg-image" alt="Calculating enterprise value with Python and Pandas (part 2). WACC and DCF"></figure><!--kg-card-end: image--><ul><li>rF equal to the risk-free interest rate in the economy (for example, the yield on Treasury bills)</li><li>E(rM) equal to the historic average of the market return, defined as the average return of a broad-based market portfolio</li></ul><blockquote>I'll leave it as parameters as I'd like to move to more interesting topics</blockquote><p>The beta value can be easily accessed from the Yahoo finance summary page. So the cost of equity can be calculated as follows:</p><!--kg-card-begin: markdown--><pre><code>from pyfinmod.yahoo_finance import YahooFinanceParser
parser = YahooFinanceParser('AAPL')
beta = parser.get_value('Beta (3Y Monthly)')

from pyfinmod.wacc import get_cost_of_equity
get_cost_of_equity(beta, risk_free_interest_rate = 0.02, market_return = 0.08)
</code></pre>
<!--kg-card-end: markdown--><h3 id="putting-it-all-together-for-wacc">Putting it all together for WACC</h3><p>Everything's ready for calculating WACC. The problem is that some parameters are time series (i.e. debt) and some are just numbers (i.e. equity and cost of equity). It would be more correct to obtain historical data for equity as well, of course. I'll just assume they are the same for all periods and return the mean value of WACC.</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.yahoo_finance import YahooFinanceParser
from pyfinmod.wacc import wacc
parser = YahooFinanceParser('AAPL')
e = parser.get_value('Market Cap')
beta = parser.get_value('Beta (3Y Monthly)')
income_statement = parser.get_dataframe('income-statement')
balance_sheet = parser.get_dataframe('balance-sheet')
aapl_wacc = wacc(e, balance_sheet, income_statement, beta,
                 risk_free_interest_rate=0.02,
                 market_return=0.08)
</code></pre>
<!--kg-card-end: markdown--><p>The result for AAPL is 8.18%.</p><h3 id="dcf">DCF</h3><p>So now we have historical free cash flows and WACC and we need to project them into the future. But to what extent? Let's assume 2 growth factors:</p><ul><li>optimistic short term (year 1-5)</li><li>pessimistic long term</li></ul><p>Then we take the latest known FCF value and project it by incrementing with short term growth rate until year 5. The rest will be represented by terminal value - FCF at year 5 multiplied by pessimistic growth rate and discounted by WACC.</p><!--kg-card-begin: markdown--><pre><code class="language-python">from pyfinmod.ev import dcf
dcf(fcf, aapl_wacc, short_term_growth=0.08, long_term_growth=0.04)
</code></pre>
<!--kg-card-end: markdown--><p>The result for AAPL is ~3.2T which is 3x its current market cap (assuming 8% growth in the next 5 years and 4% growth afterward)<br></p>]]></content:encoded></item><item><title><![CDATA[Unittesting decorators]]></title><description><![CDATA[<p>I'll start with a simple example of a class I want to put under test. A <code>Car</code> class uses <code>Engine</code> and instantiates it internally</p><!--kg-card-begin: markdown--><pre><code class="language-python">class Engine:
    def start(self):
        interact_with_outside_world()
        print('Engine started')

class Car:
    def __init__(self):
        self.engine = Engine()
    def drive(self):
        self.engine.start(</code></pre>]]></description><link>https://smirnov-am.github.io/unittesting-decorators/</link><guid isPermaLink="false">5d18b57adc96e708c93ce655</guid><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Sun, 30 Jun 2019 20:10:41 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/06/unit_testing.png" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/06/unit_testing.png" alt="Unittesting decorators"><p>I'll start with a simple example of a class I want to put under test. A <code>Car</code> class uses <code>Engine</code> and instantiates it internally</p><!--kg-card-begin: markdown--><pre><code class="language-python">class Engine:
    def start(self):
        interact_with_outside_world()
        print('Engine started')

class Car:
    def __init__(self):
        self.engine = Engine()
    def drive(self):
        self.engine.start()
</code></pre>
<!--kg-card-end: markdown--><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><p>Let's write a unittest for <code>Car</code> class. By definition, unittest shouldn't be allowed to interact with the outside world (connect . to DB, etc). There are 2 ways to solve that.<br><br>First is to subclass <code>Car</code></p><!--kg-card-begin: markdown--><pre><code class="language-python">class TestEngine:
    def start(self):
        pretend_to_interact_with_outside_world()
        print('Engine started')

class TestCar(Car):
    def __init__(self):
        super().__init__()
        self.engine = TestEngine()
</code></pre>
<!--kg-card-end: markdown--><p>Sometimes this is a viable solution. But <code>Engine</code> is still instantiated and can access real resources inside its constructor. This approach is described <a href="https://www.youtube.com/watch?v=EiOglTERPEo&amp;feature=youtu.be&amp;t=20m35s">here</a>.<br> </p><p>Dependency injection is more flexible.It is a powerful pattern that allows separate the construction of  the object of its use. The object should not be responsible for instantiating dependencies which supports Single Responsibility Principle.</p><!--kg-card-begin: markdown--><pre><code class="language-python">class Car:
    def __init__(self, engine):
        self.engine = engine
    def drive(self):
        self.engine.start()

# production code
engine = Engine()
car = Car(engine)


# unittest
def test_car():
    test_engine = TestEngine()
    test_car = Car(test_engine)
    ...
</code></pre>
<!--kg-card-end: markdown--><p>Here we can init the <code>Engine</code> outside the <code>Car</code> and provide instance of the real one in our code and test instance in unittest.</p><h3 id="decorator">Decorator</h3><p>Decorators are a nice Python feature I've been using to organize caching. Let's create a decorator that will cache the result of a calculation in Redis. First let's create an interface to Redis as well as stub interface for unittests:<br><br><em>interfaces.py</em></p><!--kg-card-begin: markdown--><pre><code class="language-python">from abc import ABCMeta, abstractmethod
import redis


class CacheInterface(metaclass=ABCMeta):
    @abstractmethod
    def get(self, key):
        pass

    @abstractmethod
    def set(self, key, value):
        pass


class RedisInterface(CacheInterface):
    def __init__(self, redis_client=None):
        if not redis_client:
            self.redis_client = redis.StrictRedis(host='localhost',
                                                  port=6379,
                                                  socket_timeout=1)
        else:
            self.redis_client = redis_client

    def get(self, key):
        print(f'Accessing Redis for key={key}')
        value = self.redis_client.get(key)
        if value:
            value = value.decode('utf-8')
        return value

    def set(self, key, value):
        print(f'Setting Redis key={key} with value={value}')
        if value:
            res = self.redis_client.set(key, value)
            return res


class TestCacheInterface(CacheInterface):
    def __init__(self):
        self.data = {}

    def get(self, key):
        print(f'Accessing local dict for key={key}')
        return self.data.get(key)

    def set(self, key, value):
        print(f'Setting local dict key={key} with value={value}')
        self.data[key] = value

</code></pre>
<!--kg-card-end: markdown--><p>The two classes <code>RedisInterface</code> and <code>TestCacheInterface</code> have the same interface (enforced by using <code>ABCmeta</code>) so can be substituted between each other (Polymorphism! Yay!).<br><br>Now let's create a decorator using a class syntax:<br><em>caching.py</em></p><!--kg-card-begin: markdown--><pre><code class="language-python">from functools import wraps
from interfaces import RedisInterface


class cache:
    def __init__(self):
        print('Initializing decorator')
        self.caching_interface = RedisInterface()

    def __call__(self, func):
        print('Running decorator __call__')

        @wraps(func)
        def wrapped(*args, **kwargs):
            cache_key = f'{func.__name__}{args}{kwargs}'
            result = self.caching_interface.get(cache_key)
            if result:
                return result
            result = func(*args, **kwargs)
            self.caching_interface.set(cache_key, result)
            return result

        return wrapped
</code></pre>
<!--kg-card-end: markdown--><p>Now this decorator can be used with a function that calculates square root of a number using Newton's method<br><br><em>caching.py</em> cont'd</p><!--kg-card-begin: markdown--><pre><code class="language-python">@cache()
def newton_sqrt(number, iters=500):
    a = float(number)
    for i in range(iters):
        number = 0.5 * (number + a / number)
    return number


if __name__ == '__main__':
    print('Starting main')
    print(newton_sqrt(42))
    print(newton_sqrt(42))
</code></pre>
<!--kg-card-end: markdown--><p>The result is:</p><!--kg-card-begin: markdown--><pre><code class="language-Initializing">Initializing decorator
Running decorator __call__
Starting main
Accessing Redis for key=newton_sqrt(42,){}
Setting Redis key=newton_sqrt(42,){} with value=6.48074069840786
6.48074069840786
Accessing Redis for key=newton_sqrt(42,){}
6.48074069840786
</code></pre>
<!--kg-card-end: markdown--><p>The problem with a decorator is that it's <code>__init__</code> and and <code>__call__</code> methods are called upon import. That is, even if I don't run the <code>newton_sqrt(42)</code> inside the <code>main</code> there is a <code>cache</code> instance somewhere in memory and the <code>newton_sqrt</code> is decorated ( <code>__call__</code> being invoked)<br><br>It looks like it would be hard to inject testing cache interface into this caching class. The cached function is already decorated, and there is no place to use dependency injection.<br><br>I've ended up using monkey patching for that. But accessing the instance of the decorator is impossible, so I've used <a href="https://www.python.org/dev/peps/pep-0232/">function attributes</a>. Since the decorated (or any function) is a class in Python it can have an attribute assigned this points to cache decorator instance.<br><br>For it I changed the decorator class:</p><!--kg-card-begin: markdown--><pre><code class="language-python">class cache:
    def __init__(self):
        self.interface = RedisInterface()

    def __call__(self, func):
        func.cache_decorator_instance = self

        @wraps(func)
        def wrapped(*args, **kwargs):
            cache_key = f'{func.__name__}{args}{kwargs}'
            result = func.cache_instance.caching_interface.get(cache_key)
            if result:
                return result
            result = func(*args, **kwargs)
            func.cache_instance.interface.set(cache_key, result)
            return result

        return wrapped
</code></pre>
<!--kg-card-end: markdown--><p><br>Now the class can be easily tested:<br><br><em>test_caching.py</em></p><!--kg-card-begin: markdown--><pre><code>from caching import newton_sqrt
from interfaces import TestCacheInterface
from pytest import approx
from math import sqrt


def test_caching():
    newton_sqrt.cache_instance.interface = TestCacheInterface()
    assert newton_sqrt(42) == approx(sqrt(42), abs=1e-6)

</code></pre>
<!--kg-card-end: markdown--><p><br>The result of the test:</p><!--kg-card-begin: markdown--><pre><code>test_caching.py .
Accessing local dict for key=newton_sqrt(42,){}
Setting local dict key=newton_sqrt(42,){} with value=6.48074069840786
                                                        [100%]

=========================== 1 passed in 0.02 seconds ===========================
Process finished with exit code 0
</code></pre>
<!--kg-card-end: markdown-->]]></content:encoded></item><item><title><![CDATA[Calculating enterprise value with Python and Pandas (part 1). FCF]]></title><description><![CDATA[<h1 id="enterprise-value">Enterprise Value</h1><p>Value of the enterprise may be used to find out whether the price of company equity - a share - is worth what market offers. It's also used in acquisitions to get the price of the company as a whole.</p><p>In this post I'll cover 3 methods of</p>]]></description><link>https://smirnov-am.github.io/calculating-enterprise-value-with-python-and-pandas-part-1-fcf/</link><guid isPermaLink="false">5cc4b3cc79d5490c32257609</guid><category><![CDATA[Financial Modelling]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Tue, 19 Feb 2019 19:55:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/pyfinmod2--1-.png" medium="image"/><content:encoded><![CDATA[<h1 id="enterprise-value">Enterprise Value</h1><img src="https://smirnov-am.github.io/content/images/2019/04/pyfinmod2--1-.png" alt="Calculating enterprise value with Python and Pandas (part 1). FCF"><p>Value of the enterprise may be used to find out whether the price of company equity - a share - is worth what market offers. It's also used in acquisitions to get the price of the company as a whole.</p><p>In this post I'll cover 3 methods of Enterprise Value calculations:</p><ul><li>using accounting book</li><li>efficient market approach</li><li>discounted cash flows (DCF)</li></ul><p>The latter one - DCF - is a complex topic. So here I'll cover the first part - getting future the cash flows from cash flow statement. WACC, resulting calculations as well as market engineering and sensitivity analysis will be covered in later posts.</p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="methods-of-corporate-valuation">Methods of corporate valuation</h2><h3 id="1-using-an-accounting-book">1. Using an accounting book</h3><p>The idea behind this method is to rewrite the balance sheet in a way that all productive items are on the left side and financial items are on the right. Productive items include net working capital, property, <a href="https://www.investopedia.com/terms/i/intangibleasset.asp">intangible assets</a> (copyright, goodwill) and other fixed assets.<br>Net working capital is defined as <strong>accounts receivable</strong> + <strong>inventories</strong> - <strong>accounts payable</strong> - <strong>taxes payable</strong>. Liquid assets such as cash will go on the right side to net financial debt.</p><p>So on the right-hand - financial side - we will have net financial debt (all short and long term debt minus liquid cash), other liabilities such as pensions, equity.</p><p>After moving all the items both columns should be in balance - column sums are equal and represent company value.</p><p>I failed to find a reliable API to get the company's balance sheet so I made a Yahoo Finance parser.</p><!--kg-card-begin: code--><pre><code>from pyfinmod.yahoo_finance import YahooFinanceParser

parser = YahooFinanceParser('AAPL', 'balance-sheet')
parser.get_dataframe()
</code></pre><!--kg-card-end: code--><p>The resulting dataframe with AAPL balance sheet is:</p><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th style="text-align:left">row name</th>
<th style="text-align:right">2018-09-29</th>
<th style="text-align:right">2017-09-30</th>
<th style="text-align:right">2016-09-24</th>
<th style="text-align:right">2015-09-26</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Cash And Cash Equivalents</td>
<td style="text-align:right">2.5913e+10</td>
<td style="text-align:right">2.0289e+10</td>
<td style="text-align:right">2.0484e+10</td>
<td style="text-align:right">2.112e+10</td>
</tr>
<tr>
<td style="text-align:left">Short Term Investments</td>
<td style="text-align:right">4.0388e+10</td>
<td style="text-align:right">5.3892e+10</td>
<td style="text-align:right">4.6671e+10</td>
<td style="text-align:right">2.0481e+10</td>
</tr>
<tr>
<td style="text-align:left">Net Receivables</td>
<td style="text-align:right">4.8995e+10</td>
<td style="text-align:right">3.5673e+10</td>
<td style="text-align:right">2.9299e+10</td>
<td style="text-align:right">3.0343e+10</td>
</tr>
<tr>
<td style="text-align:left">Inventory</td>
<td style="text-align:right">3.956e+09</td>
<td style="text-align:right">4.855e+09</td>
<td style="text-align:right">2.132e+09</td>
<td style="text-align:right">2.349e+09</td>
</tr>
<tr>
<td style="text-align:left">Other Current Assets</td>
<td style="text-align:right">1.2087e+10</td>
<td style="text-align:right">1.3936e+10</td>
<td style="text-align:right">8.283e+09</td>
<td style="text-align:right">1.4691e+10</td>
</tr>
<tr>
<td style="text-align:left">Total Current Assets</td>
<td style="text-align:right">1.31339e+11</td>
<td style="text-align:right">1.28645e+11</td>
<td style="text-align:right">1.06869e+11</td>
<td style="text-align:right">8.9378e+10</td>
</tr>
<tr>
<td style="text-align:left">Long Term Investments</td>
<td style="text-align:right">1.70799e+11</td>
<td style="text-align:right">1.94714e+11</td>
<td style="text-align:right">1.7043e+11</td>
<td style="text-align:right">1.64065e+11</td>
</tr>
<tr>
<td style="text-align:left">...</td>
<td style="text-align:right">...</td>
<td style="text-align:right">...</td>
<td style="text-align:right">...</td>
<td style="text-align:right">...</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>To calculate enterprise value <code>get_enterprise_value</code> function can be used. And I found an interesting thing about Yahoo Finance page that there are no <code>Taxes Payable</code> row and <code>Total Current Liabilities</code> do not sum up to <code>Accounts Payable</code> + <code>Short/Current Long Term Debt</code> + <code>Other Current Liabilities</code>. So my calculations might be not very precise.</p><!--kg-card-begin: code--><pre><code>from pyfinmod.yahoo_finance import YahooFinanceParser
from pyfinmod.ev import get_enterprise_value

parser = YahooFinanceParser('AAPL', 'balance-sheet')
df = parser.get_dataframe()
get_enterprise_value(df)
</code></pre><!--kg-card-end: code--><p>The result is:</p><!--kg-card-begin: code--><pre><code>2018-09-29    271960000000
2017-09-30    298811000000
2016-09-24    233939000000
2015-09-26    202067000000
</code></pre><!--kg-card-end: code--><p>Also, there is a function to calculate net working capital:</p><!--kg-card-begin: code--><pre><code>from pyfinmod.yahoo_finance import YahooFinanceParser
from pyfinmod.ev import get_net_working_capital

parser = YahooFinanceParser('AAPL', 'balance-sheet')
df = parser.get_dataframe()
get_net_working_capital(df)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>2018-09-29   -43167000000
2017-09-30   -41813000000
2016-09-24   -14106000000
2015-09-26   -13737000000
</code></pre><!--kg-card-end: code--><h3 id="2-efficient-market-approach">2. Efficient market approach</h3><p>If the company is publicly traded we can calculate market cap: number of shares multiplied by the share price. This is equity. It's different from the equity in the liabilities column from the balance sheet which represents the initial amount of money invested in a business (maybe not initial if the profits were reinvested).</p><p>The efficient market approach says that we need to substitute equity from the rewritten balance sheet as in the previous approach with the one defined by the market. Here lies the explanation of the name of the approach - a market with many participants trading company's shares who have the same information gives the most accurate evaluation of the company.</p><p>After doing the substitution new balance sheet is not in balance. In that case, net working capital is recalculated to re-balance it. The new column sum is the company's value.</p><p>As we can see in September 2018 AAPL value was 271.960B according to the balance sheet. But market cap it as 1.086T.</p><!--kg-card-begin: code--><pre><code>from pyfinmod.yahoo_finance import YahooFinanceParser
from pyfinmod.ev import get_enterprise_value_efficient_market

parser = YahooFinanceParser('AAPL', 'balance-sheet')
df = parse.get_dataframe()
get_enterprise_value_efficient_market(df, 1086*10**9)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>2017-09-30    1250764000000
2016-09-24    1191690000000
2015-09-26    1168712000000
</code></pre><!--kg-card-end: code--><p>This is a resulting enterprise value given market cap.</p><h3 id="3-discounted-cash-flows">3. Discounted cash flows</h3><p>This approach aims to evaluate a company by its ability to generate money in future.<br>It uses two terms: Future Cash Flows (<a href="https://www.investopedia.com/terms/f/freecashflow.asp">FCF</a>) and Weighted Average Cost of Capital (<a href="https://www.investopedia.com/terms/w/wacc.asp">WACC</a>)</p><p>FCFs are defined as the cash created by the company’s operating activities. WACC is the risk-adjusted discount rate appropriate to the risk of the FCFs. And the value of the company is calculated as net present value of FCFs discounted at WACC.</p><p>There is one assumption to this approach is that cash flows occur approximately mid-year. In that case, the formula for the enterprise value (EV) is:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/2019-04-29-19.27.38.jpg" class="kg-image" alt="Calculating enterprise value with Python and Pandas (part 1). FCF"></figure><!--kg-card-end: image--><p>There are two steps in getting FCFs:</p><ul><li>get historical FCFs either from pro forma or cash flow statements</li><li>project FCFs to the future assuming growth percentages</li></ul><p>I'll skip pro forma method for now</p><h4 id="fcf-from-cash-flow-statement">FCF from cash flow statement</h4><p>We need to add up these rows from the cash flow statement:</p><ul><li>Total Cash Flow From Operating Activities</li><li>Total Cash Flows From Investing Activities</li><li>Add back after-tax net interest</li></ul><p>The latter is calculated as (1 - <strong>Income tax rate</strong>) * <strong>Cash paid for Interest</strong>.<br><strong>Cash paid for interest</strong> is absolute the value of <code>Interest Expense</code>. <strong>Income tax rate</strong> equals <code>Income Tax Expense</code> / (<code>Net Income</code> + <code>Income Tax Expense</code>).</p><p><code>Income Tax Expense</code> and <code>Interest Expense</code> are taken from the  income statement. <code>Net Income</code> is taken from cash flow statement.</p><p>Example:</p><!--kg-card-begin: code--><pre><code>from pyfinmod.ev import get_fcf_from_cscf
balance_sheet_parser = YahooFinanceParser('AAPL', 'balance-sheet')
balance_sheet = balance_sheet_parser.get_dataframe()

income_statement_parser = YahooFinanceParser('AAPL', 'income-statement')
income_statement = income_statement_parser.get_dataframe()

get_fcf_from_cscf(income_statement, cash_flow)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>2018-09-29    9.614571e+10
2017-09-30    1.953155e+10
2016-09-24    2.133789e+10
2015-09-26    2.553172e+10
</code></pre><!--kg-card-end: code--><p>In the next posts, I'll cover WACC calculation and DCF method usage.<br>Code is in the repo <a href="https://github.com/smirnov-am/pyfinmod">here</a>.<br>Feel free to reach out to me over <a href="https://www.linkedin.com/in/smirnovam/">LinkedIn</a> for any questions or corrections.</p>]]></content:encoded></item><item><title><![CDATA[Basic Financial Calculations with Python and Pandas]]></title><description><![CDATA[<p>In this post I'll cover:</p><ul><li>Net present value (NPV)</li><li>Internal rate of return (IRR)</li><li>Payment schedules and loan tables</li><li>Future value</li><li>Pension and accumulation problems</li><li>Continuously compounded interest</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="net-present-value">Net present value</h2><p>Present value allows to</p>]]></description><link>https://smirnov-am.github.io/basic-financial-calculations-with-python-and-pandas/</link><guid isPermaLink="false">5cc4b22679d5490c322575ef</guid><category><![CDATA[Financial Modelling]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Mon, 24 Dec 2018 19:48:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/pyfinmod1.png" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/pyfinmod1.png" alt="Basic Financial Calculations with Python and Pandas"><p>In this post I'll cover:</p><ul><li>Net present value (NPV)</li><li>Internal rate of return (IRR)</li><li>Payment schedules and loan tables</li><li>Future value</li><li>Pension and accumulation problems</li><li>Continuously compounded interest</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="net-present-value">Net present value</h2><p>Present value allows to answer a simple question "should I put my money in a bank or invest". Let's say I have $100 and the bank gives a 12% annual interest rate. Alternatively, I can lend this money to a friend and he promises to pay $10 for 12 months. The moral aspect aside NPV gives an answer which alternative is more profitable.</p><p>The second alternative can be described as a series of cash flows:</p><ul><li>-$100 at month=0</li><li>+$10 at month=1</li><li>...</li><li>+$10 at month=12</li></ul><p>At each period value should be adjusted by the interest rate (also called the discount rate) using formula</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/2019-04-29-19.27.19.jpg" class="kg-image" alt="Basic Financial Calculations with Python and Pandas"></figure><!--kg-card-end: image--><p>This basic concept shows that $100 now is not the same as $100 promised in a year. $100 now is $110 in a year.</p><p>To calculate the discounted value I'll convert annual discount (interest) rate to daily and use the number of days elapsed as <em>t</em>. The function accepts a dataframe with a date column and a cash flow column.</p><!--kg-card-begin: code--><pre><code>def npv(dataframe, 
        annual_discount_rate, 
        cash_flow_column_name='cash flow', 
        date_column_name='date'):
    date_start = dataframe[date_column_name].min()
    mapper = lambda x: _calculate_discounted(x[cash_flow_column_name], 
                                             annual_discount_rate, 
                                             (x[date_column_name] - date_start).days)
    return dataframe[[cash_flow_column_name, date_column_name]].apply(mapper, axis=1).sum()

def _calculate_discounted(cf, annual_interest_rate, days_passed):
    daily_interest_rate = convert_ir(annual_interest_rate, from_period='year', to_period='day')
    return cf / (1 + daily_interest_rate)**days_passed
</code></pre><!--kg-card-end: code--><p>Let's calculate NPV of lending to a friend:</p><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; import pandas as pd
&gt;&gt;&gt; from datetime import date, timedelta
&gt;&gt;&gt; from dateutil.relativedelta import relativedelta
&gt;&gt;&gt; dates = [date.today() + relativedelta(months=i) for i in range(13)]
&gt;&gt;&gt; df = pd.DataFrame(data={'cash flow': [-100] + [10]*12, 
                            'date': dates})
&gt;&gt;&gt; npv(df, 0.1)
14.011086147172053
</code></pre><!--kg-card-end: code--><p>The calculated NPV of lending alternative is ~$14 which means that it is profitable. This value represents your wealth increment.  Companies use NPV<br>to calculate if it's, for example, viable to invest in a factory that will generate cash flows in the future or it's better to put the money elsewhere.</p><p><code>npv</code> function can also operate with time-dated cash flows - that is when the cash flows are not evenly placed.</p><h2 id="internal-rate-of-returns">Internal rate of returns</h2><p>So I decided to lend to a friend. What is the effective interest rate for this alternative? Internal rate of returns (IRR) answers that. The solution of the following equation for <em>r</em> gives IRR:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/2019-04-29-19.27.27.jpg" class="kg-image" alt="Basic Financial Calculations with Python and Pandas"></figure><!--kg-card-end: image--><p>Effectively we are finding interest rate when NPV is 0.</p><p>The function will accept the same dataframe as an input. I'm using scipy numerical <a href="https://docs.scipy.org/doc/scipy-0.13.0/reference/generated/scipy.optimize.fsolve.html">solver</a> to find <em>r</em>. The solver accepts the initial <em>guess</em> argument which helps to find the solution.</p><!--kg-card-begin: code--><pre><code>def irr(dataframe, guess=0, cash_flow_column_name='cash flow', date_column_name='date'):
    f = partial(npv, dataframe, cash_flow_column_name=cash_flow_column_name)
    result = fsolve(f, guess)
    return list(result)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; irr(df, 0.0)
[0.41354120272404077]
</code></pre><!--kg-card-end: code--><p>Lending to a friend has an effective interest rate of 41%</p><p>Sometimes a series of cash flows can have more than one IRR. We can play with <em>guess</em> to find both solutions.</p><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; dates = [date.today() + relativedelta(years=i) for i in range(6)]
&gt;&gt;&gt; df3 = pd.DataFrame(data={'cash flow': [-145, 100, 100, 100, 100, -275],                              'date': dates})
&gt;&gt;&gt; irr(df3, 0.1), irr(df3, 0.4)
([0.08793680470699422], [0.26585705483081506])
</code></pre><!--kg-card-end: code--><h2 id="flat-payment-schedules">Flat payment schedules</h2><p>Let's look at the lending problems from the friend's point of view. He knows that with the cash flow he proposed he will be paying 41% annual interest rate. He wants to lower the interest rate to say 30% and calculates a new flat payment scheme. Flat here means that he will pay a constant amount each month for a <em>term</em> amount of months.</p><p>First, let's calculate the monthly payment. Function argument will be</p><ul><li><em>principal</em> - the lending amount</li><li><em>annual_interest_rate</em> - agreed interest rate in a term of a year</li><li><em>term</em> - how many terms to pay</li><li><em>period</em> - unit of a <em>term</em></li></ul><!--kg-card-begin: code--><pre><code>def pmt(principal, annual_interest_rate, term, period='year'):
    periodic_interest = convert_ir(annual_interest_rate, from_period='year', to_period=period)
    payment = (principal*periodic_interest)/(1 - (1 + periodic_interest)**(-term))
    return payment
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; pmt(100, 0.3, 12, period='month')
9.57859525723352
</code></pre><!--kg-card-end: code--><p>So he will be paying ~$9.6 each month. Now he wants to know how fast he's re-paying the interest and the principal. For that, a loan table is used.</p><!--kg-card-begin: code--><pre><code>def flat_payments(principal, annual_interest_rate, term, period='year'):
    _pmt = pmt(principal, annual_interest_rate, term, period=period)
    data = defaultdict(list)
    current_principal = principal
    principal_col_name = 'principal at the beginning of {}'.format(period)
    payment_col_name = 'payment at the end of {}'.format(period)
    interest_col_name = 'interest'
    return_principal_col_name = 'return of principal'
    periodic_interest = convert_ir(annual_interest_rate, from_period='year', to_period=period)
    for _t in range(1, term + 1):
        data[period].append(_t)
        data[principal_col_name].append(current_principal)
        data[payment_col_name] = _pmt
        current_interest = current_principal * periodic_interest
        data[interest_col_name].append(current_interest)
        current_return_of_principal = _pmt - current_interest
        data[return_principal_col_name].append(current_return_of_principal)
        current_principal -= current_return_of_principal  
    assert round(current_principal) == 0
    return pd.DataFrame.from_dict(data)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; res_df = flat_payments(100, 0.3, 12, period='month')
&gt;&gt;&gt; print(tabulate(res_df, tablefmt="pipe", headers="keys"))
</code></pre><!--kg-card-end: code--><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th style="text-align:right"></th>
<th style="text-align:right">month</th>
<th style="text-align:right">principal at the beginning of month</th>
<th style="text-align:right">payment at the end of month</th>
<th style="text-align:right">interest</th>
<th style="text-align:right">return of principal</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:right">1</td>
<td style="text-align:right">100</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">2.21045</td>
<td style="text-align:right">7.36815</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:right">2</td>
<td style="text-align:right">92.6318</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">2.04758</td>
<td style="text-align:right">7.53102</td>
</tr>
<tr>
<td style="text-align:right">2</td>
<td style="text-align:right">3</td>
<td style="text-align:right">85.1008</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">1.88111</td>
<td style="text-align:right">7.69749</td>
</tr>
<tr>
<td style="text-align:right">3</td>
<td style="text-align:right">4</td>
<td style="text-align:right">77.4033</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">1.71096</td>
<td style="text-align:right">7.86764</td>
</tr>
<tr>
<td style="text-align:right">4</td>
<td style="text-align:right">5</td>
<td style="text-align:right">69.5357</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">1.53705</td>
<td style="text-align:right">8.04155</td>
</tr>
<tr>
<td style="text-align:right">5</td>
<td style="text-align:right">6</td>
<td style="text-align:right">61.4942</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">1.35929</td>
<td style="text-align:right">8.2193</td>
</tr>
<tr>
<td style="text-align:right">6</td>
<td style="text-align:right">7</td>
<td style="text-align:right">53.2749</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">1.17761</td>
<td style="text-align:right">8.40098</td>
</tr>
<tr>
<td style="text-align:right">7</td>
<td style="text-align:right">8</td>
<td style="text-align:right">44.8739</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">0.991912</td>
<td style="text-align:right">8.58668</td>
</tr>
<tr>
<td style="text-align:right">8</td>
<td style="text-align:right">9</td>
<td style="text-align:right">36.2872</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">0.802108</td>
<td style="text-align:right">8.77649</td>
</tr>
<tr>
<td style="text-align:right">9</td>
<td style="text-align:right">10</td>
<td style="text-align:right">27.5107</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">0.608109</td>
<td style="text-align:right">8.97049</td>
</tr>
<tr>
<td style="text-align:right">10</td>
<td style="text-align:right">11</td>
<td style="text-align:right">18.5402</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">0.409821</td>
<td style="text-align:right">9.16877</td>
</tr>
<tr>
<td style="text-align:right">11</td>
<td style="text-align:right">12</td>
<td style="text-align:right">9.37144</td>
<td style="text-align:right">9.5786</td>
<td style="text-align:right">0.207151</td>
<td style="text-align:right">9.37144</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><p>I'm using <a href="https://pypi.org/project/tabulate/">tabulate</a> to print dataframes in the terminal.</p><p>The last two columns - <em>interest</em> and <em>return of principal</em> - show how the payment is split between repaying interest and principal. At the end, principal value should be 0 (see assert in function code). It's interesting to know how much interest is re-payed because that amount sometimes is tax deductible.</p><h2 id="future-value">Future value</h2><p>Let’s imagine we put $10000 today for 10 years with an annual interest rate 10%. How much money we will have in 10 years? Using this formula with r=0.1 ant t=10 will give us $2593.74:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/2019-04-29-19.27.34.jpg" class="kg-image" alt="Basic Financial Calculations with Python and Pandas"></figure><!--kg-card-end: image--><p>A slightly more complex problem is if we want to deposit some money during these 10 years. The f<em>uture value</em> will tell how much money we'll have in the end of the period.</p><p>The function accepts a list of deposit amounts and, annual interest rate and a period at which deposits are made</p><!--kg-card-begin: code--><pre><code>def fv(deposits, annual_interest_rate, period='year'):
    periodic_interest = convert_ir(annual_interest_rate, from_period='year', to_period=period)
    future_value = 0
    number_of_deposits = len(deposits)
    for n, deposit in enumerate(deposits):
        future_value += deposit * (1 + periodic_interest)**(number_of_deposits - n)
    return future_value
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; fv([1000 for _ in range(10)], 0.1, period='year')
17531.16706110001
</code></pre><!--kg-card-end: code--><p>So depositing $1000 for 10 years will yield $17.5k given the interest rate is 10%.</p><h2 id="retirement-problem">Retirement problem</h2><p>Consider the following exercise. Now I'm 31 and planning to retire at 55 (24 more years working). After retiring I'm planning to live at least 25 more years and will need, say, $50000 a year. To support my retirement I need to deposit money into a bank account with known interest rate (say 5%). What's the minimum amount do I need to deposit each year?</p><p>This problem implies a number of cash flows: 24 terms with CF=<em>x</em> at each time, and 25 terms with CF=-50000. The present value of this cash flows should be 0. Solving this equation for <em>x</em> will give the minimum annual deposit. The minimum deposit is used here not in a mathematical sense, but more in common sense - I'll live more that 25 years after retirement, prices are also going up so I'll need more than 50k yearly.</p><!--kg-card-begin: code--><pre><code>def get_retirement_cf_dataframe(deposit, terms_of_deposit, withdrawal, terms_of_withdrawal, period='year'):
    cash_flows = [deposit]*terms_of_deposit + [-withdrawal]*terms_of_withdrawal
    terms = terms_of_deposit + terms_of_withdrawal
    dates = [date.today() + relativedelta(**{period + 's':i}) for i in range(terms)]
    df = pd.DataFrame(data={'cash flow': cash_flows, 'date': dates})
    return df


def retirement_problem(terms_of_deposit, 
                       withdrawal, 
                       terms_of_withdrawal, 
                       annual_discount_rate, 
                       period='year'):
    df_by_deposit = partial(get_retirement_cf_dataframe, 
                            terms_of_deposit=terms_of_deposit, 
                            withdrawal=withdrawal, 
                            terms_of_withdrawal=terms_of_withdrawal, 
                            period=period)
    f = lambda deposit: npv(retirement_dataframe_by_deposit(deposit), annual_discount_rate)
    result = fsolve(f, withdrawal)
    return list(result)
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; retirement_problem(24, 50000, 25, 0.05)
[15822.327630785972]
</code></pre><!--kg-card-end: code--><p>That's a pretty cool result - I need to deposit only ~$16k yearly for 24 years to be able to withdraw $50k for 25 years later. That's compound interest working.</p><h2 id="continuous-compounding">Continuous compounding</h2><p>I'm using <code>convert_ir(r, from_period='year', to_period='day')</code> function to convert from annual interest rate to daily interest rate in some examples above.<br>So if I have an annual rate of 20%, a quarterly rate is:</p><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; convert_ir(0.2, from_period='year', to_period='quater')
0.04663513939210562
</code></pre><!--kg-card-end: code--><p>And respective annual is:</p><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; 4 * convert_ir(0.2, from_period='year', to_period='quater')
</code></pre><!--kg-card-end: code--><p>So if a bank offers a 20% annual interest rate paid quarterly the effective annual interest rate is 18.6%. So if the number of interest payments increases - for example to every millisecond -  this is called continuous compounding. Let's calculate the annual interest rate continuously compounded given initial and end amounts.</p><!--kg-card-begin: code--><pre><code>def get_annual_rate_cc(dataframe, amount_column_name='amount', date_column_name='date'):
    amount_first = dataframe[amount_column_name].iloc[0]
    amount_last = dataframe[amount_column_name].iloc[-1]
    date_first = dataframe[date_column_name].iloc[0]
    date_last = dataframe[date_column_name].iloc[-1]
    delta = relativedelta(date_last, date_first)
    t = delta.years + delta.months/12 + delta.days/365
    r = log(amount_last/amount_first)/t
    return r
</code></pre><!--kg-card-end: code--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; df = pd.DataFrame(data={'amount': [1000, 1500], 'date': [date.today(), date.today() + relativedelta(years=1, months=9)]})
&gt;&gt;&gt; print(tabulate(df, tablefmt="pipe", headers="keys"))
</code></pre><!--kg-card-end: code--><!--kg-card-begin: markdown--><table>
<thead>
<tr>
<th style="text-align:right"></th>
<th style="text-align:right">amount</th>
<th style="text-align:left">date</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right">0</td>
<td style="text-align:right">1000</td>
<td style="text-align:left">2018-12-24</td>
</tr>
<tr>
<td style="text-align:right">1</td>
<td style="text-align:right">1500</td>
<td style="text-align:left">2020-09-24</td>
</tr>
</tbody>
</table>
<!--kg-card-end: markdown--><!--kg-card-begin: code--><pre><code>&gt;&gt;&gt; get_annual_rate_cc(df)
0.23169434749037965
</code></pre><!--kg-card-end: code--><p>Continuous compounding is used in many financial calculations.</p><h2 id="code">Code</h2><p>I'm planning to gather all the financial modeling methods including the ones form this post in a repo <a href="https://github.com/smirnov-am/pyfinmod">here</a>. Feel free to reach out to me over <a href="https://www.linkedin.com/in/smirnovam/">LinkedIn</a> for any questions.</p>]]></content:encoded></item><item><title><![CDATA[Streaming timeseries with Flask and Plotly]]></title><description><![CDATA[<p>This simple app for streaming cpu utilization to a web page. I'm using Flask as websockets server (flask-socketio plugin), socket.io as client library and plotly.js<br>for visualization.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo--2-.gif" class="kg-image"></figure><!--kg-card-end: image--><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="flask-app">Flask app</h2><p>I'm following a flask-socketio</p>]]></description><link>https://smirnov-am.github.io/streaming-timeseries-with-flask-and-plotly/</link><guid isPermaLink="false">5cc4b0c979d5490c322575c6</guid><category><![CDATA[Flask]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Wed, 12 Dec 2018 19:43:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/task-manager-3-.png" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/task-manager-3-.png" alt="Streaming timeseries with Flask and Plotly"><p>This simple app for streaming cpu utilization to a web page. I'm using Flask as websockets server (flask-socketio plugin), socket.io as client library and plotly.js<br>for visualization.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo--2-.gif" class="kg-image" alt="Streaming timeseries with Flask and Plotly"></figure><!--kg-card-end: image--><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="flask-app">Flask app</h2><p>I'm following a flask-socketio <a href="https://flask-socketio.readthedocs.io/en/latest/">doc</a> to create a flask app. SocketIO is going to use Redis as message broker as there will be a separate process that pushes messages to clients. Flask websocket server and this process will communicate through Redis.</p><!--kg-card-begin: code--><pre><code>def create_app(register_blueprint=True):
    app = Flask(__name__)
    app.secret_key = os.urandom(42)
    if register_blueprint:
        app.register_blueprint(plotting_blueprint)

    socketio = SocketIO(app, message_queue='redis://localhost:6379/')
    socketio.on_event('connect', bootstrap_on_connect)
    return socketio, app


socketio, application = create_app()


if __name__ == '__main__':
    socketio.run(application)
</code></pre><!--kg-card-end: code--><p>Here I'm defining first hook - when client connects we are going to send him some history data - the task for <code>bootstrap_on_connect</code> functions.</p><p>The blueprint I'm defining is simple one that has only one route that serves a static page. This page will load client's javascript. The only parameter is window size - I'd like to see only last 100 seconds of data.</p><!--kg-card-begin: code--><pre><code>from flask import Blueprint, render_template

plotting_blueprint = Blueprint('plotting', __name__)


@plotting_blueprint.route('/')
def index():
    return render_template('index.html', x_window=100)

</code></pre><!--kg-card-end: code--><h2 id="template-and-client-code">Template and client code</h2><p>In the template I'm putting window size inside meta tag so JS will be able to read that.<br>Also I'm loading all libraries in the end of body</p><!--kg-card-begin: code--><pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
    &lt;meta charset="UTF-8"&gt;
    &lt;meta name="x_window" content={{x_window}}&gt;
    &lt;title&gt;Flask data viz&lt;/title&gt;
    &lt;link rel="stylesheet" type="text/css" href="{{ url_for('static', filename='styles.css') }}"&gt;
&lt;/head&gt;
&lt;body&gt;
&lt;div id="plot"&gt;&lt;/div&gt;
&lt;script src="https://cdn.plot.ly/plotly-latest.min.js"&gt;&lt;/script&gt;
&lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"&gt;&lt;/script&gt;
&lt;script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/socket.io/1.3.6/socket.io.min.js"&gt;&lt;/script&gt;
&lt;script src="{{ url_for('static', filename='plot.js') }}"&gt;&lt;/script&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre><!--kg-card-end: code--><p><code>plot.js</code> will contain all client-side logic.</p><!--kg-card-begin: code--><pre><code>var url = 'http://' + document.domain + ':' + location.port
var socket = io.connect(url);

socket.on('connect', function(msg) {
    console.log('connected to websocket on ' + url);
});

socket.on('bootstrap', function (msg) {
    plot_start = msg.x[0];
    makePlotly( msg.x, msg.y )
});

socket.on('update', function (msg) {
    streamPlotly( msg.x, msg.y )
});
</code></pre><!--kg-card-end: code--><p>First we connect to websocket (using HTTP, not WS protocol). When connected Flask will send us <code>bootstrap</code> message with initial data. Here <code>makePlotly</code> function is invoked. It will initialize plotly stuff. When <code>update</code> message is received <code>streamPlotly</code> will use <code>Plotly.extendTraces</code> to add data to plotly traces. It also updates the layout so we'll have nice sliding window.</p><h2 id="running-the-app">Running the app</h2><p>To run the app I'm using uwsgi with gevent. uwsgi config:</p><!--kg-card-begin: code--><pre><code>[uwsgi]
module = app:application
uid = www-data

http = 127.0.0.1:5000

gevent-monkey-patch = true
http-websockets = true
gevent = 1000

</code></pre><!--kg-card-end: code--><p>Protocol for websockets is going to be HTTP so uwsgi will listen on port 5000 instead of communication through UNIX socket with nginx.</p><p>Nginx config should create a separate location for websocket url</p><!--kg-card-begin: code--><pre><code>server {
    listen       80 default_server;
    listen       [::]:80 default_server;
    server_name  localhost;
    root         /var/www/html;
    client_max_body_size 16M;

    location / {
        include proxy_params;
        proxy_pass http://127.0.0.1:5000;
    }

    location /socket.io {
        include proxy_params;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "Upgrade";
        proxy_set_header Host $host;
        proxy_pass http://127.0.0.1:5000/socket.io;
    }
}
</code></pre><!--kg-card-end: code--><h3 id="background-job">Background job</h3><p>A separate process gets CPU utilization with <code>psutil</code> and pushes message to clients.<br>Also it defines bootstrap function - but I'm just starting with empty lists for now.</p><p><code>streaming.py</code>:</p><!--kg-card-begin: code--><pre><code>#!/usr/bin/env python
import time
from datetime import datetime
from psutil import cpu_percent
from flask_socketio import emit, SocketIO

DATE_FMT = "%Y-%m-%d %H:%M:%S"


def bootstrap_on_connect():
    emit('bootstrap', {'x': [datetime.now().strftime(DATE_FMT)], 'y': [0]})


def update_plot():
    socketio = SocketIO(message_queue='redis://localhost:6379/')
    while True:
        datetime_now = datetime.now().strftime(DATE_FMT)
        cpu_percent_second = cpu_percent(interval=1)
        socketio.emit('update', {'x': [datetime_now], 'y': [cpu_percent_second]})
        time.sleep(1)


if __name__ == '__main__':
    update_plot()
</code></pre><!--kg-card-end: code--><h2 id="running-it-all">Running it all</h2><ol><li>Install redis server and nginx</li><li>Run uwsgi with <code>uwsgi --ini uwsgi.ini</code></li><li>Install all dependencies from requirements.txt into virtual environment</li><li>Run streaming.py (<code>chmod +x streaming.py &amp;&amp; ./streaming.py</code>)</li></ol><h2 id="further-thoughts">Further thoughts</h2><p>There is no persistence to the data and newly connected client won't be able to see the history. For this some kind of storage is needed. Another approach is to periodically call Flask from javascript to get the data though AJAX call.<br>I find a websocket solution more interesting - but more complex - because it allows<br>to have a separate process to update clients, that offloads some work from web server.</p><p>Full code is available from this <a href="https://github.com/smirnov-am/flask-streaming">repo</a></p><p>Do you use websockets for streaming live data? Connect with me on <a href="https://www.linkedin.com/in/smirnovam/">linkedin</a> to discuss it.</p>]]></content:encoded></item><item><title><![CDATA[Background jobs with Flask]]></title><description><![CDATA[<p>Basic request lifecycle with Flask goes like this:</p><ul><li>Flask get request</li><li>parse parameters</li><li>does calculations</li><li>returns result</li></ul><p>This synchronous task is fine when user needs the result of calculation immediately.<br>Another use case is when the result is not relevant right now and user just wants to schedule an execution</p>]]></description><link>https://smirnov-am.github.io/background-jobs-with-flask/</link><guid isPermaLink="false">5cc4af2c79d5490c3225758f</guid><category><![CDATA[Flask]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Tue, 27 Nov 2018 19:41:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/800px_COLOURBOX2362664.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/800px_COLOURBOX2362664.jpg" alt="Background jobs with Flask"><p>Basic request lifecycle with Flask goes like this:</p><ul><li>Flask get request</li><li>parse parameters</li><li>does calculations</li><li>returns result</li></ul><p>This synchronous task is fine when user needs the result of calculation immediately.<br>Another use case is when the result is not relevant right now and user just wants to schedule an execution of the task asynchronously.</p><p>Such scenarios include:</p><ul><li>sending email</li><li>creating thumbnails from uploaded image</li></ul><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/img1.png" class="kg-image" alt="Background jobs with Flask"></figure><!--kg-card-end: image--><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="common-implementation">Common implementation</h2><p>Asynchronous tasks are usually implemented like this:</p><ul><li>Flask schedules a task by putting a message into message broker (Redis, AWS SQS, RabbitMQ) upon request</li><li>The broker is made available to the pool of possibly separate machines - workers</li><li>Workers get messages from broker and execute tasks</li></ul><p>This approach has a number of advantages. Firstly, it's sharing responsibility. Instances running Flask web server are doing only one job - serving requests. If the tasks are resource demanding Flask instances won't suffer from high memory/CPU usage and will still server requests. Secondly, tasks are stored in message broker.<br>If Flask instances die it won't affect workers and task execution.</p><p>Nothing comes for free. This structure has more points of failure then alternatives. Libraries serving brokers have bugs. Also it may looks like a over-engineering for simple tasks.</p><p>Here are some good examples of such implementations: <a href="https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-xxii-background-jobs">RQ</a>, <a href="https://blog.miguelgrinberg.com/post/using-celery-with-flask">Celery</a></p><h2 id="alternatives">Alternatives</h2><h3 id="threads">Threads</h3><p>Most basic approach is to run a task in a thread. For that to work this line should be added to uwsgi configuration file:</p><!--kg-card-begin: code--><pre><code>enable-threads = true
</code></pre><!--kg-card-end: code--><p>we run <a href="https://smirnov-am.github.io/2018/08/09/flask-docker.html">Flask with uwsg in production</a> of course</p><p>Code <code>app.py</code></p><!--kg-card-begin: code--><pre><code>import os
import time
from flask import Flask, jsonify
from threading import Thread
from tasks import threaded_task

app = Flask(__name__)
app.secret_key = os.urandom(42)


@app.route("/", defaults={'duration': 5})
@app.route("/&lt;int:duration&gt;")
def index(duration):
    thread = Thread(target=threaded_task, args=(duration,))
    thread.daemon = True
    thread.start()
    return jsonify({'thread_name': str(thread.name),
                    'started': True})
</code></pre><!--kg-card-end: code--><p>code <code>tasks.py</code></p><!--kg-card-begin: code--><pre><code>import time

def threaded_task(duration):
    for i in range(duration):
        print("Working... {}/{}".format(i + 1, duration))
        time.sleep(1)
</code></pre><!--kg-card-end: code--><p>Demo:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo1.gif" class="kg-image" alt="Background jobs with Flask"></figure><!--kg-card-end: image--><h3 id="uwsgi-thread">uWSGI thread</h3><p>Creating and running thread may be delegated to uwsgi. So we don't interact with<br>threading module directly. For that there is a <code>thread</code> decorator available <code>from uwsgidecorators import thread</code> (<a href="https://uwsgi-docs.readthedocs.io/en/latest/PythonDecorators.html?highlight=thread#uwsgidecorators.thread">API docs</a>)</p><p>Code <code>app.py</code></p><!--kg-card-begin: code--><pre><code>import os
import time
from flask import Flask, jsonify
from threading import Thread
from tasks import uwsgi_task

app = Flask(__name__)
app.secret_key = os.urandom(42)


@app.route("/uwsgi_thread", defaults={'duration': 5})
@app.route("/uwsgi_thread/&lt;int:duration&gt;")
def uwsgi_thread(duration):
    uwsgi_task(duration)
    return jsonify({'started': True})
</code></pre><!--kg-card-end: code--><p>code <code>tasks.py</code></p><!--kg-card-begin: code--><pre><code>import time
from uwsgidecorators import thread


@thread
def uwsgi_task(duration):
    for i in range(duration):
        print("Working in uwsgi thread... {}/{}".format(i + 1, duration))
        time.sleep(1)
</code></pre><!--kg-card-end: code--><p>Demo:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo2.gif" class="kg-image" alt="Background jobs with Flask"></figure><!--kg-card-end: image--><h3 id="uwsgi-spooler">uWSGI spooler</h3><p>Above examples create a thread per request and can lead to some troubles when there are many of them. To control that a task may run in a <a href="https://uwsgi-docs.readthedocs.io/en/latest/Spooler.html?highlight=spooler">spooler</a> with controlled number of executors.<br>This however requires some configuration from uwsgi side (that is <code>uwsgi.ini</code>)</p><ul><li><code>spooler = my_spools</code> - a path to a directory to store files representing tasks. Directory should be created beforehand.</li><li><code>spooler-import = tasks.py</code> - a module containing task's code spooler workers will import</li><li><code>spooler-frequency = 1</code> - how ofter workers scan spool directory for tasks</li><li><code>spooler-processes = 10</code> - how many workers to run</li></ul><p>After running <code>uwsgi --ini uwsgi.ini</code> startup log shows created processes:</p><!--kg-card-begin: code--><pre><code>spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10609
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10610
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10611
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10612
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10613
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10614
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10615
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10616
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10617
spawned the uWSGI spooler on dir /home/as/Desktop/blog/my_spools with pid 10618
spawned uWSGI worker 1 (pid: 10619, cores: 1)
spawned uWSGI worker 2 (pid: 10620, cores: 1)
spawned uWSGI worker 3 (pid: 10621, cores: 1)
spawned uWSGI worker 4 (pid: 10622, cores: 1)
spawned uWSGI worker 5 (pid: 10623, cores: 1)
</code></pre><!--kg-card-end: code--><p><code>tasks.py</code> code is straightforward and use <code>spool</code> decorator from uwsgi.<br>The task function itself should return a predefined codes though:</p><ul><li><code>uwsgi.SPOOL_OK</code> if all went well</li><li><code>uwsgi.SPOOL_RETRY</code> if a jobs needs to be retried (if it's idempotent of course)</li></ul><!--kg-card-begin: code--><pre><code>import time
import uwsgi
from uwsgidecorators import spool


@spool
def spool_task(args):
    try:
        duration = int(args['duration'])
        for i in range(duration):
            print("Working in uwsgi spool... {}/{}".format(i + 1, duration))
            time.sleep(1)
        return uwsgi.SPOOL_OK
    except:
        return uwsgi.SPOOL_RETRY
</code></pre><!--kg-card-end: code--><p><code>app.py</code> calls <code>spool_task</code> in the route, but I struggled a but with passing parameters.<br>I was getting such error when passing them according to the docs:</p><!--kg-card-begin: code--><pre><code>ValueError: spooler callable dictionary must contains only bytes
</code></pre><!--kg-card-end: code--><p>So I came up with simple helper that converts keyword arguments to a dictionary with keys and values that have bytes only - <code>prepare_spooler_args</code>. <code>spool</code> decorator has a <code>pass_arguments</code> parameter - it may be a possible solution as well.</p><!--kg-card-begin: code--><pre><code>import os
import time
from flask import Flask, jsonify
from tasks import threaded_task, uwsgi_task, spool_task, uwsgi_tasks_task

app = Flask(__name__)
app.secret_key = os.urandom(42)


def prepare_spooler_args(**kwargs):
    args = {}
    for name, value in kwargs.items():
        args[name.encode('utf-8')] = str(value).encode('utf-8')
    return args


@app.route("/uwsgi_spool", defaults={'duration': 5})
@app.route("/uwsgi_spool/&lt;int:duration&gt;")
def uwsgi_spool(duration):
    args = prepare_spooler_args(duration=duration)
    spool_task.spool(args)
    return jsonify({'started': True})
</code></pre><!--kg-card-end: code--><p>Also <code>spool_task.spool</code> accepts an <code>at</code> parameter that tell spooler to run a task at a specified unix timestamp. To use it <code>uwsgi_spool</code> route code:</p><!--kg-card-begin: code--><pre><code>@app.route("/uwsgi_spool", defaults={'duration': 5})
@app.route("/uwsgi_spool/&lt;int:duration&gt;")
def uwsgi_spool(duration):
    at = int(time.time()) + 3 # delay by 3s
    args = prepare_spooler_args(duration=duration, at=at)
    spool_task.spool(args)
    return jsonify({'started': True})
</code></pre><!--kg-card-end: code--><p>Demo:</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo3.gif" class="kg-image" alt="Background jobs with Flask"></figure><!--kg-card-end: image--><h3 id="wrapping-up-spooler">Wrapping up spooler</h3><p><code>uwsgi-tasks</code> library (<a href="https://pypi.org/project/uwsgi-tasks/">pypi</a>) wraps all the uwsgi spooler workings, especially argument passing. Also I found controlling retries as a useful feature.<br>Unfortunately after installing it previous example (bareback spooler) stopped working for me.</p><h2 id="further-thoughts-">Further thoughts.</h2><p>uSWGI spooler is great for simple tasks. It becomes more robust with external spooler support and networking, but at that level it starts resemble a common approach with all it's drawbacks.</p><p>The whole code is available at <a href="https://github.com/smirnov-am/flask-bg-tasks">GitHub</a></p><p>Do you use background jobs with Flask? Drop me a message on <a href="https://www.linkedin.com/in/smirnovam/">linkedin</a></p>]]></content:encoded></item><item><title><![CDATA[Multitenancy with Flask]]></title><description><![CDATA[<h3 id="what-is-multitenancy">What is multitenancy</h3><p>Consider a SaaS platform that provide access to multiple client organizations.<br>These organizations - tenants - may have each its own database for safety and data protection reasons.<br>It can be a database on a single RDBMS server or physically different servers.<br>Usually additional central database (i.</p>]]></description><link>https://smirnov-am.github.io/multitenancy-with-flask/</link><guid isPermaLink="false">5cc4988279d5490c32257576</guid><category><![CDATA[Flask]]></category><category><![CDATA[python]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Fri, 26 Oct 2018 17:59:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/social-housing-landlords-tenants-scotland-act-2014-tenancy-short-secure-law-lawyer-eviction.jpg" medium="image"/><content:encoded><![CDATA[<h3 id="what-is-multitenancy">What is multitenancy</h3><img src="https://smirnov-am.github.io/content/images/2019/04/social-housing-landlords-tenants-scotland-act-2014-tenancy-short-secure-law-lawyer-eviction.jpg" alt="Multitenancy with Flask"><p>Consider a SaaS platform that provide access to multiple client organizations.<br>These organizations - tenants - may have each its own database for safety and data protection reasons.<br>It can be a database on a single RDBMS server or physically different servers.<br>Usually additional central database (i.e., General) stores metadata and list of available tenants.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/description.png" class="kg-image" alt="Multitenancy with Flask"></figure><!--kg-card-end: image--><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h3 id="flask-sqlalchemy">Flask-SQLAlchemy</h3><p>Flask-SQLAlchemy provides interface only to one database.<br>Flask app configuration defines <code>SQLALCHEMY_DATABASE_URI</code> gives connection info and database name.<br>It possible to extend it to multiple tenant databases using <a href="http://flask-sqlalchemy.pocoo.org/2.3/binds/">binds</a></p><h3 id="tenant-dependent-endpoint">Tenant dependent endpoint</h3><p>Consider this endpoint that displays tenant users and gets tenant name<br>as its parameter</p><!--kg-card-begin: code--><pre><code>@app.route("/&lt;tenant_name&gt;/users")
def index(tenant_name):
    tenant_session = get_tenant_session(tenant_name)
    if not tenant_session:
        abort(404)
    users = tenant_session.query(User).all()
    return jsonify({tenant_name: [i.username for i in users]})
</code></pre><!--kg-card-end: code--><p>Models used are very basic:</p><!--kg-card-begin: code--><pre><code>class User(db.Model):
    __tablename__ = 'users'

    id = db.Column(db.Integer, primary_key=True)
    username = db.Column(db.String(100), nullable=False)


class Tenant(db.Model):
    __tablename__ = 'tenants'

    id = db.Column(db.Integer, primary_key=True)
    name = db.Column(db.String(100), nullable=False)
</code></pre><!--kg-card-end: code--><p>For users it's just id and username. These tables are in tenant database.<br>And tenant model is in general database. I keep track of available tenants here so<br>if query refers to unknown tenant it will give 404 error.</p><h3 id="building-tenant-session">Building tenant session</h3><p>To get tenant session</p><ul><li>check if tenant name is in <code>tenants</code> table from General database</li><li>create a URI in <code>SQLALCHEMY_BINDS</code> dictionary that is in Flask app configuration - <code>current_app.config</code></li><li>get SQLAlchemy engine that reads that bind</li><li>form session from a session factory - <code>sessionmaker</code> - that uses the engine</li></ul><!--kg-card-begin: code--><pre><code>MYSQL_URI = 'mysql+pymysql://user:pwd@localhost/{}?charset=utf8'


@simple_cache
def get_known_tenants():
    tenants = Tenant.query.all()
    return [i.name for i in tenants]


def prepare_bind(tenant_name):
    if tenant_name not in current_app.config['SQLALCHEMY_BINDS']:
        current_app.config['SQLALCHEMY_BINDS'][tenant_name] = MYSQL_URI.format(tenant_name)
    return current_app.config['SQLALCHEMY_BINDS'][tenant_name]


def get_tenant_session(tenant_name):
    if tenant_name not in get_known_tenants():
        return None
    prepare_bind(tenant_name)
    engine = db.get_engine(current_app, bind=tenant_name)
    session_maker = db.sessionmaker()
    session_maker.configure(bind=engine)
    session = session_maker()
    return session
</code></pre><!--kg-card-end: code--><p>I check tenant availability at every request. This information doesn't change often so it's cached.</p><h3 id="cache-slow-changing-data">Cache slow changing data</h3><p>I'll be using simple <a href="http://werkzeug.pocoo.org/docs/0.14/contrib/cache/">werkzeug cache</a>.<br>Every process and uwsgi worker will get its own instance. To share the data between processes this cache can be easily extended to use external store like Redis/Memcached.</p><p><code>Simple_cache</code> is a decorator using function name as a key like so:</p><!--kg-card-begin: code--><pre><code>cache = SimpleCache()


def simple_cache(f):
    @wraps(f)
    def wrapper(*args, **kwargs):
        function_name = f.__name__
        if cache.has(function_name):
            result = cache.get(function_name)
        else:
            result = f(*args, **kwargs)
            cache.set(function_name, result)
        return result
    return wrapper
</code></pre><!--kg-card-end: code--><h3 id="database-initialization">Database initialization</h3><p>I've prepared a SQL dump to generate mock data <a>here</a>. It creates all databases<br>and tables with two tenants: TenantA and TenantB. Each has 2 users:</p><ul><li>userA and userB for TenantA;</li><li>userA and userC for TenantB;</li></ul><p>It can be imported with mysql client</p><p><code>mysql --host="&lt;host&gt;" --user="&lt;user&gt;" --password="&lt;password&gt;" &lt; all_databases.sql</code></p><h3 id="results">Results</h3><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo--1-.gif" class="kg-image" alt="Multitenancy with Flask"></figure><!--kg-card-end: image--><p>The whole code is available at <a href="https://github.com/smirnov-am/flask-multitenancy">GitHub</a></p><p>Do you use multitenant database? Drop me a message on <a href="https://www.linkedin.com/in/smirnovam/">LinkedIn</a></p>]]></content:encoded></item><item><title><![CDATA[Flask pagination macro]]></title><description><![CDATA[<p>In this post I will cover how to create a pagination with Jinja macro feature.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo.gif" class="kg-image"></figure><!--kg-card-end: image--><p>Requirements:</p><ul><li>show preconfigured limited number of pages at once</li><li>collapse invisible pages under <code>...</code></li><li>provide previous/next navigation buttons</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="jinja-templates-for-bootstrap4">Jinja templates</h2>]]></description><link>https://smirnov-am.github.io/flask-pagination-macro/</link><guid isPermaLink="false">5cc492f079d5490c32257553</guid><category><![CDATA[Flask]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Thu, 27 Sep 2018 17:35:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/Pager-in-hand-684x513.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/Pager-in-hand-684x513.jpg" alt="Flask pagination macro"><p>In this post I will cover how to create a pagination with Jinja macro feature.</p><!--kg-card-begin: image--><figure class="kg-card kg-image-card"><img src="https://smirnov-am.github.io/content/images/2019/04/demo.gif" class="kg-image" alt="Flask pagination macro"></figure><!--kg-card-end: image--><p>Requirements:</p><ul><li>show preconfigured limited number of pages at once</li><li>collapse invisible pages under <code>...</code></li><li>provide previous/next navigation buttons</li></ul><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="jinja-templates-for-bootstrap4">Jinja templates for Bootstrap4</h2><p>I've created 3 tier structure of Jinja templates to use Bootstrap4.<br><strong>First</strong> - <code>bootstrap4_base.html</code> - loads css and js files from CDN and defines major blocks:</p><ul><li><code>head</code> - holds content of the <code>&lt;head&gt;</code> tag and defines <code>title</code>, <code>metas</code>, <code>styles</code></li><li><code>body</code> - holds content of the <code>&lt;body&gt;</code> tag and defines <code>navbar</code>, <code>content</code>, <code>scripts</code></li><li><code>navbar</code> - for navigation bar</li><li><code>content</code> - for boostrap container (tag with <code>class="container"</code>)</li><li><code>scripts</code> - goes in the end of the body, <a href="https://stackoverflow.com/questions/383045/is-put-scripts-at-the-bottom-correct">here is why</a></li></ul><p>Blocks may be extended or/and overwritten in the later templates<br>This template follows Bootstrap4 <a href="https://getbootstrap.com/docs/4.0/getting-started/introduction/">intro guide</a></p><p><strong>Second</strong> - <code>page_base.html</code> - creates navbar and extends <code>content</code> block.<br>It shows all the flash messages (the ones invoked with flask <code>flash</code> function) and adds <code>page_content</code>.<br>That one will be extended in the last template and holds actual content.</p><p><strong>Third</strong> - <code>index.html</code> - will overwrite <code>title</code> block and extend <code>page_content</code></p><p>Hierarchy of templates is achieved with using of <code>{% extends "&lt;parent_template.html" %}</code> block to refer to parent template.</p><p>To extend a block - <code>scripts</code> for example - inside child template:</p><!--kg-card-begin: code--><pre><code>{% block scripts %}
    {{ super() }}
    &lt;script&gt;
        alert(1);
    &lt;/script&gt;
(% endblock %)
</code></pre><!--kg-card-end: code--><p>Drop <code>super</code> to just overwrite it.</p><h2 id="jinja-pagination-macro">Jinja pagination macro</h2><p>Macros are comparable with functions in regular programming languages. They are useful to put often used idioms into reusable functions to not repeat yourself (“DRY”).<br>Macro is a bare block that starts with <code>{% macro function_name(formal_params) %}</code>. It holds the HTML, or rather templated Jinja code that will be reused.<br>I'm putting it's code into separate file - <code>_macros.html</code>.</p><p>Usage:</p><ol><li>import it with <code>{% import "_macros.html" as macros %}</code></li><li>call it with <code>{{ macros.function_name(actual_params) }}</code></li></ol><p>Bootstrap pagination follows that <a href="https://getbootstrap.com/docs/4.0/components/pagination/#working-with-icons">doc</a></p><p>I've tried to put as little logic in the macro itself and do all the calculations in the flask view.<br>My version needs 2 params:</p><ol><li><code>endpoint</code> - the name of flask endpoint provided to <code>url_for</code> which builds the actual link to select page</li><li><code>pages</code> list if dictionaries, each one has</li></ol><ul><li><code>class</code> key to define if link is active, normal or disabled</li><li><code>page_label</code> show the page number or navigation icons</li><li><code>href</code> - additional param for <code>url_for</code> which will hold page</li></ul><p>Macro code:</p><!--kg-card-begin: code--><pre><code>{% macro pagination_widget(pages, endpoint) %}
&lt;nav aria-label="Page navigation example"&gt;
    &lt;ul class="pagination"&gt;
        {% for p in pages %}
        &lt;li class="page-item {{p['class']}}"&gt;
            &lt;a href="{{ url_for(endpoint, page = p['href'], **kwargs) }}"
                class="page-link"
                aria-label={{p['page']}}&gt;
                &lt;span aria-hidden="true"&gt;{{p['page_label'] | safe}}&lt;/span&gt;
                &lt;span class="sr-only"&gt;{{p['page_label'] | safe}}&lt;/span&gt;

            &lt;/a&gt;
        &lt;/li&gt;
        {% endfor %}
    &lt;/ul&gt;
&lt;/nav&gt;
{% endmacro %}
</code></pre><!--kg-card-end: code--><h3 id="flask-endpoint">Flask endpoint</h3><p>Endpoint code relies on a <code>Pager</code> class to prepare <code>pages</code>. It first needs to get the page number from URL parameters.  The actual data I'm using is just a list of numbers up to a <code>count</code>. In real world it's going to be a query to the database like <code>SELECT column from table LIMIT Y OFFSET X</code>.<br>Where X - is a page size * current page (zero based), Y - is a page_size.</p><p>OFFSET may be slow with big numbers - it's better to use <a href="https://blog.jooq.org/2013/10/26/faster-sql-paging-with-jooq-using-the-seek-method/">Sleek mode</a></p><p>Flask endpoint:</p><!--kg-card-begin: code--><pre><code>@app.route("/")
def index():
    page = int(request.args.get('page', 1))

    count = 300
    data = range(count)

    pager = Pager(page, count)
    pages = pager.get_pages()

    offset = (page - 1) * current_app.config['PAGE_SIZE']
    limit = current_app.config['PAGE_SIZE']
    data_to_show = data[offset: offset + limit]

    return render_template('index.html', pages=pages, data_to_show=data_to_show)
</code></pre><!--kg-card-end: code--><h3 id="pager-class">Pager class</h3><p>This class prepares a <code>pages</code> list for macro. To do the calculations it needs the number of all items and the current page. Page size and a number of visible pages are read from app config.</p><p>Difficult part was to show exactly predefined number if links to another pages. Invisible pages are collapsed under <code>...</code>.</p><h3 id="app-configuration">App configuration</h3><p>App config contains two parameters:</p><ol><li><code>PAGE_SIZE</code> - how many elements show in a page</li><li><code>VISIBLE_PAGE_COUNT</code> - how may links to pages how in pages inculding <code>...</code>s</li></ol><!--kg-card-begin: code--><pre><code>app = Flask(__name__)
app.secret_key = os.urandom(42)
app.config['PAGE_SIZE'] = 20
app.config['VISIBLE_PAGE_COUNT'] = 10
</code></pre><!--kg-card-end: code--><p>The whole code is available at <a href="https://github.com/smirnov-am/flask-pager">GitHub</a></p><p>Do you have another useful macro? Drop me a message on <a href="https://www.linkedin.com/in/smirnovam/">LinkedIn</a></p>]]></content:encoded></item><item><title><![CDATA[Running Flask in production with Docker]]></title><description><![CDATA[<p>Google top for running Flask with Docker is full of posts where Flask runs in debug mode.<br>That what logs look like when Flask is in development mode:</p><!--kg-card-begin: code--><pre><code> * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production</code></pre>]]></description><link>https://smirnov-am.github.io/running-flask-in-production-with-docker/</link><guid isPermaLink="false">5cc491f679d5490c32257548</guid><category><![CDATA[Flask]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Mon, 13 Aug 2018 17:31:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/kitflask.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/kitflask.jpg" alt="Running Flask in production with Docker"><p>Google top for running Flask with Docker is full of posts where Flask runs in debug mode.<br>That what logs look like when Flask is in development mode:</p><!--kg-card-begin: code--><pre><code> * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:5555/ (Press CTRL+C to quit)
</code></pre><!--kg-card-end: code--><p>I'd like to make a tutorial on how to run it with uwsgi in Docker using common Docker images.</p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="flask-app">Flask app</h2><p>I'll take a basic Flask app from it's official <a href="http://flask.pocoo.org/">docs</a></p><!--kg-card-begin: code--><pre><code>from flask import Flask
app = Flask(__name__)

@app.route("/")
def hello():
    return "Hello World!"
</code></pre><!--kg-card-end: code--><p>Naming this file as <code>hello.py</code> and running it with <code>FLASK_APP=test.py flask run --port 5555</code> will yield a warning that development server is used in a production environment like above.</p><h2 id="uwsgi">uwsgi</h2><p>As suggested by the warning we should use <code>uwsgi</code> to run it. For that to happen let's create a uwsgi configuration file named <code>uwsgi.ini</code></p><!--kg-card-begin: code--><pre><code>[uwsgi]
module = hello:app
uid = www-data
gid = www-data
master = true
processes = 5

socket = /tmp/uwsgi.socket
chmod-sock = 664
vacuum = true

die-on-term = true
</code></pre><!--kg-card-end: code--><p>So running uwsgi app with <code>uwsgi --ini uwsgi.ini</code> will give long output indicating that uwsgi started 5 processes (see <code>processes=5</code> in the config). Development server runs only 1 process thus allowing only 1 request at a time. By increasing this number you will increase the number if simultaneous requests to Flask app, but that will require more RAM and there will be more processes with Python interpreter running.</p><p>There is also a backlog for uwsgi meaning that if all workers (uwsgi processes) are busy with requests, excessive requests will be put in a queue of size 100 by default. Requests above that level will be dropped by uwsgi, but we will eventually have nginx in front of it with it's own backlog.</p><!--kg-card-begin: code--><pre><code>[uWSGI] getting INI configuration from uwsgi.ini                                             
*** Starting uWSGI 2.0.17.1 (64bit) on [Fri Aug  3 22:29:18 2018] ***                        
compiled with version: 7.2.0 on 03 August 2018 22:23:17                                      
os: Linux-4.13.0-46-generic #51-Ubuntu SMP Tue Jun 12 12:36:29 UTC 2018                      
nodename: ubuntuvm                                                                                                                                                                           
machine: x86_64                                                                              
clock source: unix                            
detected number of CPU cores: 4               
current working directory: /home/as/Desktop/blog                                    
detected binary path: /home/as/.virtualenvs/blog/bin/uwsgi                          
!!! no internal routing support, rebuild with pcre support !!!                               
your processes number limit is 63569          
your memory page size is 4096 bytes  
detected max file descriptor number: 1024     
lock engine: pthread robust mutexes                                                          
thunder lock: disabled (you can enable it with --thunder-lock)                               
uwsgi socket 0 bound to UNIX address /tmp/uwsgi.socket fd 3                                  
Python version: 3.6.3 (default, Oct  3 2017, 21:45:48)  [GCC 7.2.0]                          
*** Python threads support is disabled. You can enable it with --enable-threads ***          
Python main interpreter initialized at 0x562fb447cb40        i     i         i               
your server socket listen backlog is limited to 100 connections                              
your mercy for graceful operations on workers is 60 seconds                                  
mapped 437520 bytes (427 KB) for 5 cores                                                     
*** Operational MODE: preforking ***                                                         
WSGI app 0 (mountpoint='') ready in 1 seconds on interpreter 0x562fb447cb40 pid: 23917 (default app)                                                                                       
*** uWSGI is running in multiple interpreter mode ***                                        
spawned uWSGI master process (pid: 23917)     
spawned uWSGI worker 1 (pid: 23923, cores: 1) 
spawned uWSGI worker 2 (pid: 23924, cores: 1)                     
spawned uWSGI worker 3 (pid: 23925, cores: 1)                     
spawned uWSGI worker 4 (pid: 23926, cores: 1)                     
spawned uWSGI worker 5 (pid: 23927, cores: 1) 
</code></pre><!--kg-card-end: code--><p>Also this will create a socket file, that will be referred later in nginx configuration.</p><!--kg-card-begin: code--><pre><code>~ ls -la /tmp/uwsgi.socket  
srwxrwxr-x 1 as as 0 aug  3 22:29 /tmp/uwsgi.socket
</code></pre><!--kg-card-end: code--><p>Another thing is the user which runs <code>uwsgi</code> processes and owns a socket. Ideally you need to use user with minimum access right. With <code>uid</code>/<code>gid</code> options I've specified <code>www-data</code> - standard user used by web servers. If you run uwsgi manually from bash it will use your user for socket and processes. But in Docker we will run it as root so these options are needed to downgrade it to <code>www-data</code>.</p><p>Also I've seen that some distributions clean /tmp or some daemons have different view but it's not the case with the base distribution for the image I'm using.</p><p>Uwsgi has a lot of configuration options. There is a good list you need to check if you need to troubleshoot/tune your application that can be found <a href="https://uwsgi-docs.readthedocs.io/en/latest/ThingsToKnow.html">here</a></p><h2 id="nginx">nginx</h2><p>Nginx will serve as a proxy to uwsgi. It's nginx that will listen on ports 80/443 and forward requests to the socket.<br>It's config (named <code>nginx.conf</code>) is pretty straightforward (I'm omitting SSL config)</p><!--kg-card-begin: code--><pre><code>user www-data;
worker_processes auto;
pid /run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    access_log /dev/stdout;
    error_log /dev/stdout;

    sendfile            on;
    tcp_nopush          on;
    tcp_nodelay         on;
    keepalive_timeout   65;
    types_hash_max_size 2048;

    include             /etc/nginx/mime.types;
    default_type        application/octet-stream;

    index   index.html index.htm;

    server {
        listen       80 default_server;
        listen       [::]:80 default_server;
        server_name  localhost;
        root         /var/www/html;

        location / {
            include uwsgi_params;
            uwsgi_pass unix:/tmp/uwsgi.socket;
        }
    }
}
</code></pre><!--kg-card-end: code--><p>I've added redirection of access and error logs to stdout so both will be accessible through <code>docker logs</code> command. Uwsgi logs are streamed to stdout by default.</p><p>One interesting thing I found is about long lasting requests. Nginx itself may kill these requests. So it's worth adding this config to <code>location</code> block:</p><!--kg-card-begin: code--><pre><code>uwsgi_read_timeout 1h;
uwsgi_send_timeout 1h;
proxy_send_timeout 1h;
proxy_read_timeout 1h;
</code></pre><!--kg-card-end: code--><h2 id="startup-script">Startup script</h2><p>This is a simple startup script that will be used as default for executing container.<br>Name of the file will be <code>start.sh</code> and it will be referred in Dockerfile.</p><!--kg-card-begin: code--><pre><code>#!/usr/bin/env bash
service nginx start
uwsgi --ini uwsgi.ini
</code></pre><!--kg-card-end: code--><h2 id="requirements">requirements</h2><p>Requirements file (<code>requirements.txt</code>) will have only flask and uwsgi and will look like this:</p><!--kg-card-begin: code--><pre><code>click==6.7
Flask==1.0.2
itsdangerous==0.24
Jinja2==2.10
MarkupSafe==1.0
uWSGI==2.0.17.1
Werkzeug==0.14.1
</code></pre><!--kg-card-end: code--><h2 id="dockerfile">Dockerfile</h2><p>I've tried a couple of ready-made images from Docker hub and found them overcomplicated or edited in a way by their maintainers making them unusable. So I'll start with basic python image.</p><!--kg-card-begin: code--><pre><code>FROM python:3.6-slim
</code></pre><!--kg-card-end: code--><p>First thing let's copy <code>hello.py</code>, <code>uwsgi.ini</code>, <code>requirements.txt</code> and <code>start.sh</code> to working directory:</p><!--kg-card-begin: code--><pre><code>COPY . /srv/flask_app
WORKDIR /srv/flask_app
</code></pre><!--kg-card-end: code--><p>Base image doesn't have nginx and some useful packages</p><!--kg-card-begin: code--><pre><code>RUN apt-get clean \
    &amp;&amp; apt-get -y update

RUN apt-get -y install nginx \
    &amp;&amp; apt-get -y install python3-dev \
    &amp;&amp; apt-get -y install build-essential
</code></pre><!--kg-card-end: code--><p>Now let's install python requirements</p><!--kg-card-begin: code--><pre><code>RUN pip install -r requirements.txt --src /usr/local/src
</code></pre><!--kg-card-end: code--><p>Finally, copy nginx config to the proper location, add execution rights to startup script and set is as default.</p><!--kg-card-begin: code--><pre><code>COPY nginx.conf /etc/nginx
RUN chmod +x ./start.sh
CMD ["./start.sh"]
</code></pre><!--kg-card-end: code--><h2 id="building-and-running">Building and running</h2><p>Image build can be done like so:</p><!--kg-card-begin: code--><pre><code>docker build . -t flask_image
</code></pre><!--kg-card-end: code--><p>It creates an image named <code>flask_image</code> that can be run with this command:</p><p><code>docker run --name flask_container -p 80:80 flask_image</code></p><p>Now you may navigate to <a href="http://localhost">http://localhost</a> in you browser to see the output.</p><p>Some useful options when running container</p><ul><li><code>--name</code> gives the container a name that can be found in <code>docker ps</code> output</li><li><code>-p</code> instructs to publish port 80. Second 80 after semicolons tells what port nginx inside the container listens on</li><li><code>-d</code> runs container detached from terminal. Logs then can be viewed by issuing <code>docker logs</code> command</li></ul><h2 id="advantages-of-dockerized-flask">Advantages of dockerized Flask</h2><p>I found it very useful to run Flask like that for a number of reasons:</p><p>Portability: spinning projects on a different machine with different distribution is a piece of cake, provided docker is installed.</p><p>No need to configure process managers (upstart/systemd)</p><p>Automatic restart of failed containers. Just use <code>--restart on-failure</code> with <code>docker run</code></p><p>It's very easy to start with almost serverless AWS ECS Fargate.</p><h2 id="troubleshooting">Troubleshooting</h2><p>When running docker container we specified port 80 so you host should have this port available for docker to bind to on you host. If it's not then change it to something else.</p><p>If your host runs multiple containers they should listen on different ports and some kind if proxy should be running on host OS to direct requests to the proper container.</p><p>To get inside the container issue <code>docker exec -it flask_container /bin/bash</code>. To get the exact container name issue <code>docker ps</code></p><p>To follow error and access logs issue <code>docker logs -f flask_container</code></p><p>How do you run Flask in production? Drop me a message on LinkedIn <a href="https://www.linkedin.com/in/smirnovam/">https://www.linkedin.com/in/smirnovam/</a></p>]]></content:encoded></item><item><title><![CDATA[Securing Flask web applications]]></title><description><![CDATA[<p>I've just recently finished a web security training and in this post I'd like to investigate security mechanisms of my beloved web framework - Flask.<br>I'll go through different types of possible vulnerabilities and the way they can be mitigated.</p><blockquote>Improve Python code quality by running flake8 on pull requests</blockquote>]]></description><link>https://smirnov-am.github.io/securing-flask-web-applications/</link><guid isPermaLink="false">5cc490b479d5490c3225752d</guid><category><![CDATA[python]]></category><category><![CDATA[Flask]]></category><category><![CDATA[Security]]></category><dc:creator><![CDATA[Alexey Smirnov]]></dc:creator><pubDate>Wed, 11 Jul 2018 17:26:00 GMT</pubDate><media:content url="https://smirnov-am.github.io/content/images/2019/04/flask11.jpg" medium="image"/><content:encoded><![CDATA[<img src="https://smirnov-am.github.io/content/images/2019/04/flask11.jpg" alt="Securing Flask web applications"><p>I've just recently finished a web security training and in this post I'd like to investigate security mechanisms of my beloved web framework - Flask.<br>I'll go through different types of possible vulnerabilities and the way they can be mitigated.</p><blockquote>Improve Python code quality by running flake8 on pull requests <a href="https://github.com/apps/tongschar">https://github.com/apps/tongschar</a></blockquote><h2 id="xss">XSS</h2><p>Cross-Site Scripting (XSS) attacks are a type of injection, in which malicious scripts are injected into otherwise benign and trusted websites. <a href="https://www.owasp.org/index.php/Cross-site_Scripting_%28XSS%29">source</a></p><h3 id="exploit">Exploit</h3><p>Consider a form asking for a user input.</p><!--kg-card-begin: code--><pre><code>&lt;form method="post" action="/"&gt;
  &lt;input type="text" name="tweet"&gt;&lt;br&gt;
  &lt;input type="submit"&gt;
&lt;/form&gt;
</code></pre><!--kg-card-end: code--><p>And a template to show tweets by other users where user input from above form passed unprocessed:</p><!--kg-card-begin: code--><pre><code>&lt;title&gt;Hello from flask twitter&lt;/title&gt;
{% for tweet in tweets %}
  &lt;h1 class={{tweet}}&gt;{{ tweet }}!&lt;/h1&gt;
  &lt;a href="{{tweet}}"&gt;Like&lt;/a&gt;
{% endfor %}
</code></pre><!--kg-card-end: code--><p>With the Flask app looking like this:</p><!--kg-card-begin: code--><pre><code>from flask import Flask, request, render_template, make_response
app = Flask(__name__)

tweets = []


@app.route('/', methods=['GET', 'POST'])
def tweet_feed():
    if request.method == 'POST':
        tweet = request.form['tweet']
        tweets.append(tweet)
    return render_template('tweet_feed.html', tweets=tweets)

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5005, debug=True)
</code></pre><!--kg-card-end: code--><p>The tweet posted by user will be used as <code>h1</code> class attribute and inside the tag and also as <code>a</code> href attribute.</p><p>A hacker may post malicious code and when another users will open the page with tweets that code may be executed by their browsers:</p><ol><li><code>" onload=alert(1)</code> - if this appears in class attribute it will close the double quote and add a callback to onload event for this DOM.</li><li><code>javascript:alert(1);</code> - if this javascript URI appears in href attribute, browser will execute a code when user clicks.</li><li><code>&lt;script&gt;alert(1)&lt;/script&gt;</code> - if this appears anywhere on the page the script will be executed.</li></ol><p>The script may not just show an alert message, but for example do an AJAX call to another endpoint on this site (i.e. password change).  This allows the attacker to perform any action as the user on this website.</p><h3 id="mitigation">Mitigation</h3><p>When rendering templates Flask configures Jinja2 to automatically escape all values unless explicitly told otherwise. Auto-escaping is not enabled for all templates.<br>The following extensions for templates trigger auto-escaping: .html, .htm, .xml, .xhtml. Templates loaded from a string will have auto-escaping disabled.</p><p>So because of the above exploit using code #3 will be escaped and never executed.</p><p>Code #1 gives me <code>ERR_BLOCKED_BY_XSS_AUDITOR</code> error in Chrome Version 65.0.3325.181. This browser behavior can be manipulated by the server with <code>X-XSS-Protection</code> header <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-XSS-Protection">source</a></p><p>The only vulnerable part is href attribute in <code>a</code> tag.<br>We have a following option to mitigate</p><ul><li>do not use user input with <code>href</code></li><li>use <code>{{ url_for('endpoint')}}</code> when rendering template. This has additional benefit of automatically building proper URLs if endpoint path changes.</li><li>use  <code>Content-Security-Policy</code> header in response:</li></ul><!--kg-card-begin: code--><pre><code>@app.route('/', methods=['GET', 'POST'])
def tweet_feed():
    if request.method == 'POST':
        tweet = request.form['tweet']
        tweets.append(tweet)
    response = make_response(render_template('tweet_feed.html', tweets=tweets))
    response.headers['Content-Security-Policy'] = "default-src 'self'"
    return response
</code></pre><!--kg-card-end: code--><p>Content Security Policy (CSP) is security mechanism aimed at protecting from XSS and Clickjacking attacks. CSP allows you to specify trusted origins of loading resources such as Javascript, fonts, CSS and others. And also ban the execution of the built-in Javascript code. <a href="https://web-security.guru/en/web-security/content-security-policy">source</a></p><p><code>default-src 'self'</code> in <code>Content-Security-Policy</code> header in server response instructs browser to load and execute scripts from the same source - your server, which is identified by protocol (http/https), hostname and port triplet. It also disables inline scripts like the one from malicious code #3.</p><p>Another types of XSS are the ones where malicious code is embedded in uploaded file (text, images). I'll address them in File upload section later</p><h2 id="csrf">CSRF</h2><p>Cross-Site Request Forgery is an attack that allows an attacker to make requests to various sites under victim user. If the victim comes to a site containing a malicious code, a request is sent from her username to another service (social network) performing a destructive action.<br>Unlike XSS the malicious code is stored on hacker controlled server where user is tricked to visit.</p><h2 id="exploit-1">Exploit</h2><p>Consider a online bank transfer page. You may access it by logging beforehand with the authentication information stored in cookie files.</p><!--kg-card-begin: code--><pre><code>&lt;!doctype html&gt;
&lt;title&gt;Hello from Flask&lt;/title&gt;
&lt;h1&gt;Account balance {% raw %}${{ balance }}{% endraw %}&lt;/h1&gt;

&lt;h2&gt;New transfer&lt;/h2&gt;
&lt;form method="post" action="/"&gt;
  &lt;input type="text" name="destination_account" placeholder="Destination account"&gt;&lt;br&gt;
  &lt;input type="number" name="amount"&gt;&lt;br&gt;
  &lt;input type="submit" value="Transfer"&gt;
&lt;/form&gt;
</code></pre><!--kg-card-end: code--><p>With Flaks app looking like this:</p><!--kg-card-begin: code--><pre><code>from flask import Flask, request, render_template
app = Flask(__name__)

account_balance = 1000


@app.route('/', methods=['GET', 'POST'])
def transfer():
    global account_balance
    if request.method == 'POST':
        transferred_amount = request.form['amount']
        if transferred_amount.isdigit():
            account_balance -= int(transferred_amount)
    response = make_response(render_template('transfer.html', balance=account_balance))
    return response


if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5005, debug=True)
</code></pre><!--kg-card-end: code--><p>Now an attacker may trick you to follow a link to his website (I'm getting a lot of 'Your transaction is approved, Follow this link for details' spam messages recently).<br>When you follow the link a page with the following script loads:</p><!--kg-card-begin: code--><pre><code>&lt;form method="POST" action="http://0.0.0.0:5005/" id="hacker_form"&gt;
   &lt;input type="text" name="destination_account" value="123123123"/&gt;
   &lt;input type="number" name="amount" value="1000"/&gt;
   &lt;input type="submit" value="Transfer"&gt;
&lt;/form&gt;
&lt;script&gt;document.getElementById("hacker_form").submit()&lt;/script&gt;
</code></pre><!--kg-card-end: code--><p>So when sending this form to bank app at <a href="http://0.0.0.0:5005/">http://0.0.0.0:5005/</a> authorization cookie will be also sent along. Thus user authorized bank to transfer $10000 to Account #123123123</p><h3 id="mitigation-1">Mitigation</h3><p>I've used endpoint that changes the state of account only on POST request. That complicated hacker's task a little bit as he needs user to visit his server with malicious code.<br>If it was just GET user only needs to click the link without loading the script from hacker's server.</p><p>Another security measure is to use tokens with each account state change endpoint.<br>With every form user gets a random token (as a form's hidden field) and when form is POSTed, the token is checked for validity and expiration.<br>In Flask this is implemented in <a href="http://flask-wtf.readthedocs.io/en/stable/">Flask-WTF plugin</a></p><p>Outline</p><ol><li>GET requests should not change the state of the system</li><li>Check <code>Origin</code> and/or <code>Referer</code> request header in server code to match real server name</li><li>Use CSRF-tokens</li></ol><h2 id="sql-injection">SQL Injection</h2><p>SQL Injection occurs when attacker-controlled input is inserted into a SQL query without proper validation or sanitization. This often occurs when using string formatting or concatenation to build queries.<br>An attacker may be able to read data for which they are not authorized, tamper with or destroy data, or possibly even write files or execute code on the database server. The impact is dependent on the exact scenario, but is generally quite severe.</p><h3 id="exploit-2">Exploit</h3><p>Consider bank transfer form from the above example with the following Flask app (I'm using SQLAlchemy here and trying to put things simple, but usually it's not how you manage database session in Flask app)</p><!--kg-card-begin: code--><pre><code>from flask import Flask, request, render_template, make_response, redirect, url_for
from sqlalchemy import Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine

app = Flask(__name__)
Base = declarative_base()
engine = create_engine('sqlite:///123.db', echo=True)

@app.route('/', methods=['GET', 'POST'])
def transfer():
    session = sessionmaker(bind=engine)()
    account_balance_query = session.execute('SELECT balance from accounts WHERE number=1111')
    account_balance = int(account_balance_query.fetchone()[0])
    if request.method == 'POST':
        transferred_amount = request.form['amount']
        destination_account = request.form['destination_account']
        session.execute('UPDATE accounts SET balance = balance - ' + transferred_amount + ' WHERE number=1111')
        session.execute('UPDATE accounts SET balance = balance + ' + transferred_amount + ' WHERE number=' + destination_account)
        session.commit()
        session.close()
        return redirect(url_for('transfer'))
    response = make_response(render_template('transfer.html', balance=account_balance))
    session.close()
    return response

</code></pre><!--kg-card-end: code--><p>I've tried to break all the rules here: building raw queries and concatenating query string with user input directly (I might have used <code>.format</code> as well).<br>So when entering <code>2222;DROP DATABASE;</code> in destination account input field I expected this particular line<br><code>session.execute('UPDATE accounts SET balance = balance + ' + transferred_amount + ' WHERE number=' + destination_account)</code><br>execute an update and then drop database.<br>But it gave me that error <code>sqlite3.Warning: You can only execute one statement at a time.</code> and no changes were made to database.<br>Not all drivers have that protection, while <a href="http://dev.mysql.com/doc/connector-python/en/connector-python-api-mysqlcursor-execute.html">some</a> allow multiple statement to be executed like so.</p><h3 id="mitigation-2">Mitigation</h3><p>The proper way to avoid that is to use ORMs. In that case the Flask app will be like this:</p><!--kg-card-begin: code--><pre><code>from flask import Flask, request, render_template, make_response, redirect, url_for
from sqlalchemy import Column, Integer, String
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine

app = Flask(__name__)
Base = declarative_base()
engine = create_engine('sqlite:///123.db', echo=True)


class Account(Base):
    __tablename__ = 'accounts'
    id = Column(Integer, primary_key=True, autoincrement=True)
    number = Column(String(64))
    balance = Column(Integer)


@app.route('/', methods=['GET', 'POST'])
def transfer():
    session = sessionmaker(bind=engine)()
    account = session.query(Account).filter_by(number='1111').one()
    if request.method == 'POST':
        transferred_amount = int(request.form['amount'])
        account.balance -= transferred_amount
        destination_account_number = request.form['destination_account']
        destination_account = session.query(Account).filter_by(number=destination_account_number).one()
        destination_account.balance += transferred_amount
        session.commit()
        session.close()
        return redirect(url_for('transfer'))
    session.close()
    response = make_response(render_template('transfer.html', balance=account.balance))
    return response
</code></pre><!--kg-card-end: code--><h2 id="directory-traversal">Directory traversal</h2><p>Directory traversal may happen when for example an attacker uploads a file with a filename like <code>../../../etc/passwd</code>. If he guessed the number of <code>..</code> right he might overwrite the file (given that uwsgi or Flask is running as root, but it may be any other file like <code>~/bash.rc</code>).<br>The mitigation is explained in official Flask docs <a href="http://flask.pocoo.org/docs/1.0/patterns/fileuploads/">here</a></p><p>Essentially you need to sanitize filenames from file upload form. Another advice is avoid using user provided filenames at all and generate your own (hash of the datetime/username/etc) and store them on a separate subdomain (more on it later)</p><h2 id="xss-in-uploaded-files">XSS in uploaded files</h2><p>This is not particularly related to Flask, but malicious javascript might appear not only in reflected output or stored in database (see general XSS attack), but it can also be embedded in images.<br>For example, <a href="https://marcoramilli.blogspot.com/2014/01/hacking-through-image-gif-turn.html">this blog post</a><br>uses that <a href="https://pastebin.com/6yUbfGX5">code</a> to embed javascript in GIF image file. CSP won't help here - so the only way is to serve the images from separate subdomain (that's what actually Facebook does)</p><p>Another thing related to files is how to you actually serve them. A pdf document uploaded by an attacker may have malicious code so if that file is server to another users it's better to add <code>Content-Disposition: attachment</code> header to server response so browser will download it instead of showing right away.</p><h2 id="cookie-protection">Cookie protection</h2><p>Cookie files are used for a lot of things along with storing session or authentication data.<br>There are some methods to protect them from exposing to an attacker</p><h3 id="secure">Secure</h3><p>Cookies are sent with every request in clear text:</p><!--kg-card-begin: code--><pre><code>GET /index.html HTTP/1.1
Host: www.example.org
Cookie: session=XXXXXXX
</code></pre><!--kg-card-end: code--><p>It means that if an attacker that controls network equipment between you and server (or your ISP) can easily read it.<br>Setting cookie <code>secure</code> flag will instruct browser to send a cookie only over protected HTTPS connection.</p><h3 id="http-only">HTTP Only</h3><p><code>HttpOnly</code> flag will instruct browser to hide cookie content from javascript code. In case of XSS attack it will prevent an attacker from accessing sensitive data stored in it.</p><h3 id="samesite">SameSite</h3><p>In the CSRF example the critical part of the attack was that user's cookie was send from attacker controlled site. It can be mitigated by setting <code>SameSite=strict</code>.<br>Another option for that flag is 'lax' which won't allow sending cookies from another sites when doing requests other than <code>GET</code>.</p><p>Flask by default uses <code>session</code> cookie and its flags are set by configuring <code>app</code>:</p><!--kg-card-begin: code--><pre><code>app.config.update(
    SESSION_COOKIE_SECURE=True,
    SESSION_COOKIE_HTTPONLY=True,
    SESSION_COOKIE_SAMESITE='Lax',
)
</code></pre><!--kg-card-end: code--><p>User defined cookies are set with response:</p><!--kg-card-begin: code--><pre><code>response.set_cookie('key', 'value', secure=True, httponly=True, samesite='Lax')
</code></pre><!--kg-card-end: code--><p>Have your Flask apps ever been hacked? Drop me a message on LinkedIn <a href="https://www.linkedin.com/in/smirnovam/">https://www.linkedin.com/in/smirnovam/</a></p>]]></content:encoded></item></channel></rss>